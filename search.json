[
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "",
    "text": "The purpose of this module is to introduce the basics of Elo ratings in the context of measuring NFL team strengths. This file contains guided exercises demonstrating how to implement Elo ratings from scratch in R.\nWe’ll use a subset of the NFL Game Outcomes dataset available on the SCORE Sports Data Repository, only considering games during the 2023-24 season. The following code chunk reads in the larger dataset and filters down to only include games during the 2023-24 season:\n\n# Need to have the tidyverse installed prior to starting!\nlibrary(tidyverse)\n\nnfl_games <- read_csv(\"https://data.scorenetwork.org/data/nfl_mahomes_era_games.csv\") |>\n  filter(season == 2023)\n\nAs indicated in the overview page for the larger dataset, each row in the dataset corresponds to a single game played during the 2023-24 season:\n\nnfl_games\n\n# A tibble: 285 × 10\n   season game_id      game_type  week home_team away_team home_score away_score\n    <dbl> <chr>        <chr>     <dbl> <chr>     <chr>          <dbl>      <dbl>\n 1   2023 2023_01_DET… REG           1 KC        DET               20         21\n 2   2023 2023_01_CAR… REG           1 ATL       CAR               24         10\n 3   2023 2023_01_HOU… REG           1 BAL       HOU               25          9\n 4   2023 2023_01_CIN… REG           1 CLE       CIN               24          3\n 5   2023 2023_01_JAX… REG           1 IND       JAX               21         31\n 6   2023 2023_01_TB_… REG           1 MIN       TB                17         20\n 7   2023 2023_01_TEN… REG           1 NO        TEN               16         15\n 8   2023 2023_01_SF_… REG           1 PIT       SF                 7         30\n 9   2023 2023_01_ARI… REG           1 WAS       ARI               20         16\n10   2023 2023_01_GB_… REG           1 CHI       GB                20         38\n# ℹ 275 more rows\n# ℹ 2 more variables: game_outcome <dbl>, score_diff <dbl>\n\n\nNote the game_type column indicates if the game was during the regular season (REG), or during the playoffs with the different values indicating the different playoff rounds:\n\ntable(nfl_games$game_type)\n\n\nCON DIV REG  SB  WC \n  2   4 272   1   6 \n\n\nThe week column just increases in the correct order, which will be convenient for implementing Elo ratings over the course of the NFL season."
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#background-information",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#background-information",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Background Information",
    "text": "Background Information\nElo ratings were created by physicist Arpad Elo in the 1960s for rating chess players. The main idea behind Elo ratings is to create an exchange in rating points between players (or teams) after a match. The simplest version of this system was constructed to be a zero-sum rating, such that the winner gains x points while the same number of x points are subtracted from the loser’s rating. If the win was expected, the winner receives fewer points than if the win was unexpected (i.e., an upset) - where the expectation is set prior to the match. This system results in a dynamic rating that is adjusted for opponent quality."
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#method-details",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#method-details",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Method Details",
    "text": "Method Details\nWe’re going to consider a simple version of Elo ratings in the context of measuring NFL team strength via a rating. Let the rating for the home team be \\(R_{\\text{home}}\\) and the away team rating be \\(R_{\\text{away}}\\). Then the expected score for the home team \\(E_{\\text{home}}\\) is calculated as:\n\\[\nE_{\\text{home}} = \\frac{1}{1+10^{\\left(R_{\\text{away}}-R_{\\text{home}}\\right) / 400}},\n\\]\nand the expected score for the away team \\(E_{\\text{away}}\\) is computed in a similar manner:\n\\[\nE_{\\text{away}} = \\frac{1}{1+10^{\\left(R_{\\text{home}}-R_{\\text{away}}\\right) / 400}}.\n\\] These expected scores represent the probability of winning1, e.g., \\(E_{\\text{home}}\\) represents the probability of winning for the home team.\nThe choice of 10 and 400 in the denominator may appear arbitrary at first, but they correspond to:\n\na logistic curve (thus bounded by 0 and 1) with base 10, and\na scaling factor of 400 which can be tuned to yield better predictions (discussed in more detail below).\n\nA more general representation of the expected score would replace the choice of 10 with some constant (e.g., \\(e\\)) and replace 400 with a tune-able quantity \\(d\\). For now though we will just use 10 and 400 since they are the original choices.\nWhile the above quantities represent the expectation of a game between teams with ratings \\(R_{\\text{home}}\\) and \\(R_{\\text{away}}\\), we need a step to update the ratings after observing the game outcome. We can update we update the ratings for the home team based on the observed score \\(S_{\\text{home}}\\):\n\\[\nR^{\\text{new}}_{\\text{home}} = R_{\\text{home}} + K \\cdot (S_{\\text{home}} - E_{\\text{home}})\n\\]\nThe observed score \\(S_{\\text{home}}\\) is based on the game outcome such that,\n\n\\(S_{\\text{home}} = 1\\) if the home team wins,\n\\(S_{\\text{home}} = 0.5\\) if it is a draw, or\n\\(S_{\\text{home}} = 0\\) if the home team loses.\n\nWe compute the updated rating for the away team \\(R^{\\text{new}}_{\\text{away}}\\) in a similar manner, by replacing home team quantities with those with respect to the away team.\nThe quantity \\(K\\) is known as the update factor, indicating the maximum number of Elo rating points a team gains from winning a single game (and how many points are subtracted if they lose). This is a tuning parameter, which ideally should be selected to yield optimal predictive performance.\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: Given the above equation for \\(R^{\\text{new}}_{\\text{home}}\\), what do you think will happen as you increase \\(K\\)? Does a single game cause a larger or smaller change on a team’s rating? Likewise, what do you think will happen if you decrease \\(K\\)? Describe what you expect to observe in 1-3 sentences.\nANSWER: The update factor \\(K\\) controls how sensitive the ratings should be to a single game outcome. A larger choice of \\(K\\) will lead to a larger change in a team’s rating following a single game, and likewise a smaller choice of \\(K\\) will lead to a smaller change in a team’s rating.\n\n\nAlthough the details are beyond the scope of this module, there is a relationship between this Elo ratings update formula with stochastic gradient descent for logistic regression."
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#learn-by-doing",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#learn-by-doing",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Learn by Doing",
    "text": "Learn by Doing\nWe’ll now proceed to implement Elo ratings for NFL teams during the 2023-24 season in R.\n\nCalculating and Updating Ratings\nWe will start by creating two helper functions to compute the expected scores and updated ratings after a game.\n\n\n\n\n\n\nActive Exercise\n\n\n\nFirst, based on the above formulas for expected score, complete the function calc_expected_score that takes in as input a team_rating and opp_team_rating then returns the expected score for the team relative to the opp_team. For ease, your function should use the base 10 logistic curve and scaling factor of 400 as fixed quantities.\n\ncalc_expected_score <- function(team_rating, opp_team_rating) {\n  1 / (1 + 10^((opp_team_rating - team_rating) / 400))\n}\n\nQUESTION: Using your function calc_expected_score, what is the expected score for a team with a rating of 1400 playing against an opposing team with a rating of 1600?\nANSWER:\n\ncalc_expected_score(1400, 1600)\n\n[1] 0.2402531\n\n\nThe expected score for the team is about 0.24, indicating that the team with a rating of 1400 has an estimated 24% chance of beating an opponent with a rating of 1600.\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nNext, complete the calc_new_rating function that takes in an initial team_rating, the observed_score and expected_score with respect to that team, along with a choice of the update_factor \\(K\\) to return the new rating. For now, we will just consider \\(K = 20\\) as the default choice.\n\ncalc_new_rating <- function(team_rating, observed_score, expected_score,\n                            update_factor = 20) {\n  team_rating + update_factor * (observed_score - expected_score)\n}\n\nQUESTION: Using your functions calc_expected_score and calc_new_rating together, what is the new rating for team that had an initial rating of 1300 but beat an opponent with a rating of 1700? You should answer this question using \\(K = 20\\), and pass in the output of calc_expected_score to be the expected_score. How does the observed change in the team’s rating compare to the maximum number of points the rating can change by?\nANSWER:\n\ncalc_new_rating(1300, 1, calc_expected_score(1300, 1700))\n\n[1] 1318.182\n\n\nThe team’s rating improves to roughly 1318 after winning. Since the maximum number of possible points is \\(K = 20\\), this is indicative of how beating a team with a rating of 1700 was relatively unexpected and nearly earned the team the maximum possible 20 points.\n\n\n\n\nNFL Elo Ratings\nNow with the basics, let’s move on to perform these calculations over the entire season, updating a table to include each team’s Elo rating following every game. We can implement this using a for loop to proceed through each game in the nfl_games table, looking up each team’s previous ratings and performing the above calculations.\nPrior to beginning this loop, we will set-up a table initializing each team with a rating of 1500. This a naive approach since we likely have prior knowledge about each team’s strength before the start of the season, but we’ll discuss this in more detail at the end of the module. For now, we’ll use 1500 since it is a common choice for initializing Elo ratings. The code chunk below initializes this starting table of ratings beginning with an imaginary week 0:\n\nnfl_elo_ratings <- tibble(team = unique(nfl_games$home_team),\n                          elo_rating = 1500,\n                          week = 0)\nnfl_elo_ratings\n\n# A tibble: 32 × 3\n   team  elo_rating  week\n   <chr>      <dbl> <dbl>\n 1 KC          1500     0\n 2 ATL         1500     0\n 3 BAL         1500     0\n 4 CLE         1500     0\n 5 IND         1500     0\n 6 MIN         1500     0\n 7 NO          1500     0\n 8 PIT         1500     0\n 9 WAS         1500     0\n10 CHI         1500     0\n# ℹ 22 more rows\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: The code chunk below outlines the for loop to be used in updating team ratings after every game during the 2023-24 season in the nfl_games dataset. Fill in the missing portions code marked by ??? using your above calc_expected_score and calc_new_rating functions. While this module does not cover all of the basics of tidyverse data wrangling, the code comments should help make the various steps clear.\nANSWER:\n\nfor (game_i in 1:nrow(nfl_games)) {\n   \n  # Grab the home and away teams in the current game:\n  home_team <- nfl_games$home_team[game_i]\n  away_team <- nfl_games$away_team[game_i]\n  # What was the observed score by the home team?\n  observed_home_score <- nfl_games$game_outcome[game_i]\n  # Retain the week number for this game:\n  game_week <- nfl_games$week[game_i]\n  \n  # What was each team's rating from their latest game in the\n  # current elo ratings table, starting with the home team:\n  home_rating <- nfl_elo_ratings |>\n    filter(team == home_team) |>\n    # Sort in descending order\n    arrange(desc(week)) |>\n    # Grab the latest game\n    slice(1) |>\n    # Just return the elo rating\n    pull(elo_rating)\n  \n  # Same thing for away team\n  away_rating <- nfl_elo_ratings |>\n    filter(team == away_team) |>\n    arrange(desc(week)) |>\n    slice(1) |>\n    pull(elo_rating)\n  \n  # Now get their new ratings, starting with the home team:\n  new_home_rating <- calc_new_rating(home_rating, observed_home_score, \n                                     calc_expected_score(home_rating,\n                                                         away_rating))\n  # And repeating for the away team using the opposite input as home team:\n  new_away_rating <- calc_new_rating(away_rating, 1 - observed_home_score, \n                                     calc_expected_score(away_rating,\n                                                         home_rating))\n  \n  # Set up a table containing the updated ratings for each team after the game\n  updated_ratings <- tibble(team = c(home_team, away_team),\n                            elo_rating = c(new_home_rating, new_away_rating),\n                            # Store the week index of the game\n                            week = rep(game_week, 2))\n  \n  # Add each teams new ratings to the current elo ratings table by row binding:\n  nfl_elo_ratings <- nfl_elo_ratings |>\n    bind_rows(updated_ratings)\n  \n}\n\n\n\nAfter you run the completed for loop, you can view and inspect the ratings in different ways. For example, the following code chunk will return the final rating for each after the completion of the entire season of games:\n\nnfl_elo_ratings |>\n  group_by(team) |>\n  # Since some teams make the playoffs, need to find the rating \n  # for each team's final weeK:\n  summarize(final_rating = elo_rating[which.max(week)]) |>\n  # Sort in descending order of the rating so the best team is first:\n  arrange(desc(final_rating))\n\n# A tibble: 32 × 2\n   team  final_rating\n   <chr>        <dbl>\n 1 KC           1576.\n 2 BAL          1575.\n 3 SF           1564.\n 4 DET          1561.\n 5 BUF          1547.\n 6 DAL          1546.\n 7 CLE          1532.\n 8 HOU          1528.\n 9 MIA          1525.\n10 LA           1523.\n# ℹ 22 more rows\n\n\n\n\n\n\n\n\nBONUS: Expand To Visualize Ratings\n\n\n\n\n\nIt is often helpful to visualize how the team ratings are changing over time. While this module does not cover the details about the ggplot2 visualization library, the following code creates a line for each team:\n\nnfl_elo_ratings |>\n  # Input the dataset into ggplot, mapping the week to the x-axis and\n  # the elo_rating to the y-axis, colored by team:\n  ggplot(aes(x = week, y = elo_rating, color = team)) +\n  geom_line() +\n  theme_bw() +\n  labs(x = \"Week\", y = \"Elo rating\",\n       title = \"NFL Elo ratings in 2023-24 season\")\n\n\n\n\nWhile we can observe ratings changing over the season for every team, this visualization is less than ideal. Instead one could take advantage of the team colors available using the load_teams function from the nflverse This is a little more involved, but here is example way to create a figure highlighting teams in each division separately (this requires installing the nflreadr, ggrepel, and cowplot packages:\n\nlibrary(nflreadr)\nnfl_team_colors <- load_teams() |>\n  dplyr::select(team_abbr, team_division, team_color)\n\n# Create a dataset that has each team's final Elo rating\nnfl_team_final <- nfl_elo_ratings |>\n  group_by(team) |>\n  summarize(week = max(week),\n            elo_rating = elo_rating[which.max(week)],\n            .groups = \"drop\") |>\n  inner_join(nfl_team_colors, by = c(\"team\" = \"team_abbr\")) |>\n  arrange(desc(elo_rating))\n \n# Need ggrepel:\nlibrary(ggrepel)\ndivision_plots <- \n  lapply(sort(unique(nfl_team_final$team_division)),\n         function(nfl_division) {                            \n             # Pull out the teams in the division\n             division_teams <- nfl_team_final |>\n               filter(team_division == nfl_division) |>\n               mutate(team = fct_reorder(team, desc(elo_rating))) \n             \n             # Get the Elo ratings data just for these teams:\n             division_data <- nfl_elo_ratings |>\n               filter(team %in% division_teams$team) |>\n               mutate(team = factor(team,\n                                    levels = levels(division_teams$team))) |>\n               # Make text labels for them:\n               group_by(team) |>\n               mutate(team_label = if_else(week == max(week),\n                                           as.character(team), \n                                           NA_character_)) |>\n               ungroup()\n             \n             # Now make the full plot\n             nfl_elo_ratings |>\n               # Plot all of the other teams as gray lines:\n               filter(!(team %in% division_teams$team)) |>\n               ggplot(aes(x = week, y = elo_rating, group = team)) +\n               geom_line(color = \"gray\", alpha = 0.5) +\n               # But display the division teams with their colors:\n               geom_line(data = division_data,\n                         aes(x = week, y = elo_rating, group = team,\n                             color = team)) +\n               geom_label_repel(data = division_data,\n                                aes(label = team_label,\n                                    color = team), nudge_x = 1, na.rm = TRUE,\n                                direction = \"y\") +\n               scale_color_manual(values = division_teams$team_color,\n                                  guide = FALSE) +\n               theme_bw() +\n               labs(x = \"Week\", y = \"Elo rating\",\n                    title = paste0(\"Division: \", nfl_division)) \n         })\n# Display the grid of plots with cowplot!\nlibrary(cowplot)\nplot_grid(plotlist = division_plots, ncol = 2, align = \"hv\")"
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#assessing-the-ratings",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#assessing-the-ratings",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Assessing the Ratings",
    "text": "Assessing the Ratings\nThe result of the for loop from above provides us with a dataset that contains the rating for each team after every week. But how do we know if we can trust this approach for estimating team ratings? We can assess the predictive performance of the Elo ratings based on the estimated probabilities for every game given the team’s ratings entering the game.\n\n\n\n\n\n\nChallenge: Missing Team ratings\n\n\n\nTo demonstrate this, we will first need to fill in for missing weeks for teams due to bye weeks. You can see in the output from the table counts below that during certain weeks there are fewer than 32 teams with ratings (this is not a concern in the values post week 18 since that corresponds to playoffs):\n\ntable(nfl_elo_ratings$week)\n\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n32 32 32 32 32 28 30 26 32 28 28 28 32 26 30 32 32 32 32 12  8  4  2 \n\n\nThe follow code chunks fixes this issue by iterating over each possible week, and fills in missing week ratings with the last available rating. There are multiple ways to do this! The details of the code are not necessarily important for understanding how to assess the accuracy of Elo ratings but rather a practical concern with implementation. If you are not interested in how the code works, feel free to just run it for usage in the remaining steps.\n\n# First get a vector of the unique teams from the table:\nnfl_teams <- unique(nfl_elo_ratings$team)\n\n# Now iterate over the weeks and decide how to grab the team ratings\ncomplete_nfl_elo_ratings <- \n  map_dfr(unique(nfl_elo_ratings$week),\n          function(week_i) {\n            \n            # How many teams have ratings in the week?\n            covered_teams <- nfl_elo_ratings |>\n              filter(week == week_i) |>\n              pull(team) |>\n              unique()\n            \n            if (length(nfl_teams) == length(covered_teams)) {\n              # Just return the rows from the nfl_elo_ratings table:\n              nfl_elo_ratings |>\n                filter(week == week_i)\n              \n            } else {\n              # Otherwise, we need to fill in the missing teams\n              # First get the latest ratings for every team prior to this week:\n              latest_ratings <- nfl_elo_ratings |>\n                filter(week < week_i) |>\n                group_by(team) |>\n                summarize(elo_rating = elo_rating[which.max(week)],\n                          .groups = \"drop\") |>\n                mutate(week = week_i)\n              \n              # Now gather the ratings for teams that are not missing this week:\n              week_ratings <- nfl_elo_ratings |>\n                filter(week == week_i)\n              \n              # Join together the missing ratings and return:\n              week_ratings |>\n                bind_rows(filter(latest_ratings,\n                                 !(latest_ratings$team %in% week_ratings$team)))\n              \n            }\n\n          })\n\n# And this now fixes the previous problem:\ntable(complete_nfl_elo_ratings$week)\n\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n\n\n\n\nWe will now make two copies of the complete_nfl_elo_ratings table - one to use for home teams and another to use for away teams. The code chunk below initializes these copies, and also adds 1 to the week column to indicate which week to use team’s rating for when predicting:\n\nhome_elo_ratings <- complete_nfl_elo_ratings |>\n  mutate(week = week + 1) |>\n  # Rename the team and elo_rating columns\n  rename(home_team = team,\n         home_elo_rating = elo_rating)\n\n# And repeat for away teams:\naway_elo_ratings <- complete_nfl_elo_ratings |>\n  mutate(week = week + 1) |>\n  rename(away_team = team,\n         away_elo_rating = elo_rating)\n\nNext, we can join the ratings stored in these two tables to the nfl_games table to estimate the expected outcome with respect to the home team. The following code chunk demonstrates how to left_join the team ratings, and then compute the probability of winning for the home team:\n\nupd_nfl_games <- nfl_games |>\n  # First join home team by the team abbreviation and week\n  left_join(home_elo_ratings, by = c(\"home_team\", \"week\")) |>\n  # Repeat for away team ratings:\n  left_join(away_elo_ratings, by = c(\"away_team\", \"week\")) |>\n  # And now compute the expectation, home_win_prob:\n  mutate(home_win_prob = calc_expected_score(home_elo_rating,\n                                             away_elo_rating))\nupd_nfl_games\n\n# A tibble: 285 × 13\n   season game_id      game_type  week home_team away_team home_score away_score\n    <dbl> <chr>        <chr>     <dbl> <chr>     <chr>          <dbl>      <dbl>\n 1   2023 2023_01_DET… REG           1 KC        DET               20         21\n 2   2023 2023_01_CAR… REG           1 ATL       CAR               24         10\n 3   2023 2023_01_HOU… REG           1 BAL       HOU               25          9\n 4   2023 2023_01_CIN… REG           1 CLE       CIN               24          3\n 5   2023 2023_01_JAX… REG           1 IND       JAX               21         31\n 6   2023 2023_01_TB_… REG           1 MIN       TB                17         20\n 7   2023 2023_01_TEN… REG           1 NO        TEN               16         15\n 8   2023 2023_01_SF_… REG           1 PIT       SF                 7         30\n 9   2023 2023_01_ARI… REG           1 WAS       ARI               20         16\n10   2023 2023_01_GB_… REG           1 CHI       GB                20         38\n# ℹ 275 more rows\n# ℹ 5 more variables: game_outcome <dbl>, score_diff <dbl>,\n#   home_elo_rating <dbl>, away_elo_rating <dbl>, home_win_prob <dbl>\n\n\nWe can now assess the use of the Elo rating system with the computed home_win_prob values relative to the observed game_outcome. While there are a number of ways to evaluate the performance of a probability estimate, in this module we will consider the use of the Brier score which is computed as the mean squared difference between the observed outcome and predicted probabilities. In the context of our Elo rating system notation, the Brier score is computed across \\(N\\) games as:\n\\[\n\\frac{1}{N} \\sum_{i = 1}^{N} (S_{\\text{home},i} - E_{\\text{home},i})^2\n\\] where the use of subscript \\(i\\) refers to the outcome and expectation for the home team in game \\(i\\).\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: Given the above formula for computing the Brier score, what do you think is a better indicator predictive accuracy: a lower or higher Brier score?\nANSWER: It is more optimal to achieve a lower Brier score as this indicates the predicted probabilities are closer to the observed outcome.\n\n\nWe will compute the Brier score using our NFL Elo ratings, and compare the performance to always using a 50/50 probability for every game, i.e., as if we never learned any information over the course of the season.\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: Compute and report the Brier score for both: (1) the Elo rating based home_win_prob and (2) as if you predicted the probability to be 0.5 for every game. Which approach performs better? Are you surprised by the outcome?\nANSWER:\nThe following code chunk computes the Brier score for both approaches:\n\nupd_nfl_games |>\n  summarize(elo_brier_score = mean((game_outcome - home_win_prob)^2),\n            base_brier_score = mean((game_outcome - 0.5)^2))\n\n# A tibble: 1 × 2\n  elo_brier_score base_brier_score\n            <dbl>            <dbl>\n1           0.245             0.25\n\n\nWe can see that the Elo ratings based Brier score is slightly lower than the 50/50 baseline. This is not surprising and should be re-assuring! We learn information about teams over the course of the season and this leads to better performance in predicting game outcomes.\n\n\nAlthough you have just implemented and evaluated the use of Elo ratings in the context of NFL games, so far we have just considered an update factor of \\(K = 20\\). But is there a more optimal choice?\n\n\n\n\n\n\nChallenging Active Exercise\n\n\n\n\n\nQUESTION: You will now proceed to different choices for the update factor. Rather than tediously code the entire process from above multiple times, we will wrap up the code to compute the Brier score for a given choice of \\(K\\) inside a function compute_elo_brier_score. The code chunk in the ANSWER portion below provides you with a template to fill out, this function takes in both the nfl_games data and input for the update_factor \\(K\\). Once you have completed the function, compute and report the Brier score for \\(K =\\) 5, 20, 50, and 100 (your value for \\(K = 20\\) should match the previous output). Which choice of \\(K\\) yields the best Brier score?\nANSWER:\nThe following is the complete version of the template code:\n\ncompute_elo_brier_score <- function(games_table, update_factor) {\n  # First initialize the ratings:\n  nfl_elo_ratings <- tibble(team = unique(games_table$home_team),\n                            elo_rating = 1500,\n                            week = 0)\n  \n  # Loop through to construct the Elo ratings:\n  for (game_i in 1:nrow(games_table)) {\n    \n    # Grab the home and away teams in the current game:\n    home_team <- games_table$home_team[game_i]\n    away_team <- games_table$away_team[game_i]\n    # What was the observed score by the home team?\n    observed_home_score <- games_table$game_outcome[game_i]\n    # Retain the week number for this game:\n    game_week <- games_table$week[game_i]\n    \n    # What was each team's rating from their latest game in the\n    # current elo ratings table, starting with the home team:\n    home_rating <- nfl_elo_ratings |>\n      filter(team == home_team) |>\n      # Sort in descending order\n      arrange(desc(week)) |>\n      # Grab the latest game\n      slice(1) |>\n      # Just return the elo rating\n      pull(elo_rating)\n    \n    # Same thing for away team\n    away_rating <- nfl_elo_ratings |>\n      filter(team == away_team) |>\n      arrange(desc(week)) |>\n      slice(1) |>\n      pull(elo_rating)\n    \n    # Now get their new ratings, starting with the home team:\n    new_home_rating <- calc_new_rating(home_rating, observed_home_score, \n                                       calc_expected_score(home_rating,\n                                                           away_rating),\n                                       update_factor)\n    # And repeating for the away team using the opposite input as home team:\n    new_away_rating <- calc_new_rating(away_rating, 1 - observed_home_score, \n                                       calc_expected_score(away_rating,\n                                                           home_rating),\n                                       update_factor)\n    \n    # Set up a table containing the updated ratings for each team after the game\n    updated_ratings <- tibble(team = c(home_team, away_team),\n                              elo_rating = c(new_home_rating, new_away_rating),\n                              # Store the week index of the game\n                              week = rep(game_week, 2))\n    \n    # Add each teams new ratings to the current elo ratings table by row binding:\n    nfl_elo_ratings <- nfl_elo_ratings |>\n      bind_rows(updated_ratings)\n    \n  }\n  \n  # Fill in the missing ratings for teams:\n  \n  # First get a vector of the unique teams from the table:\n  nfl_teams <- unique(nfl_elo_ratings$team)\n  \n  # Now iterate over the weeks and decide how to grab the team ratings\n  complete_nfl_elo_ratings <- \n    map_dfr(unique(nfl_elo_ratings$week),\n            function(week_i) {\n              \n              # How many teams have ratings in the week?\n              covered_teams <- nfl_elo_ratings |>\n                filter(week == week_i) |>\n                pull(team) |>\n                unique()\n              \n              if (length(nfl_teams) == length(covered_teams)) {\n                # Just return the rows from the nfl_elo_ratings table:\n                nfl_elo_ratings |>\n                  filter(week == week_i)\n                \n              } else {\n                # Otherwise, we need to fill in the missing teams\n                # First get the latest ratings for every team prior to this week:\n                latest_ratings <- nfl_elo_ratings |>\n                  filter(week < week_i) |>\n                  group_by(team) |>\n                  summarize(elo_rating = elo_rating[which.max(week)],\n                            .groups = \"drop\") |>\n                  mutate(week = week_i)\n                \n                # Now gather the ratings for teams that are not missing this week:\n                week_ratings <- nfl_elo_ratings |>\n                  filter(week == week_i)\n                \n                # Join together the missing ratings and return:\n                week_ratings |>\n                  bind_rows(filter(latest_ratings,\n                                   !(latest_ratings$team %in% week_ratings$team)))\n                \n              }\n              \n            })\n  \n  \n  # Join the home and away team ratings for every game to get the probabilities:\n  home_elo_ratings <- complete_nfl_elo_ratings |>\n    mutate(week = week + 1) |>\n    # Rename the team and elo_rating columns\n    rename(home_team = team,\n           home_elo_rating = elo_rating)\n  \n  # And repeat for away teams:\n  away_elo_ratings <- complete_nfl_elo_ratings |>\n    mutate(week = week + 1) |>\n    rename(away_team = team,\n           away_elo_rating = elo_rating)\n  \n  # Compute and return the Brier score\n  games_table |>\n    # First join home team by the team abbreviation and week\n    left_join(home_elo_ratings, by = c(\"home_team\", \"week\")) |>\n    # Repeat for away team ratings:\n    left_join(away_elo_ratings, by = c(\"away_team\", \"week\")) |>\n    # And now compute the expectation, home_win_prob:\n    mutate(home_win_prob = calc_expected_score(home_elo_rating,\n                                               away_elo_rating)) |>\n    summarize(brier_score = mean((game_outcome - home_win_prob)^2)) |>\n    pull(brier_score)\n}\n\n# Return the Brier score across the values for K:\ncompute_elo_brier_score(nfl_games, 5)\n\n[1] 0.2478319\n\ncompute_elo_brier_score(nfl_games, 20)\n\n[1] 0.244792\n\ncompute_elo_brier_score(nfl_games, 50)\n\n[1] 0.2470157\n\ncompute_elo_brier_score(nfl_games, 100)\n\n[1] 0.258864\n\n\nAlthough the Brier score is close between 5, 20, and 50, we can see that 20 yields the lowest Brier score. Notably, \\(K = 100\\) yields a Brier score that is worse than guessing 50/50 for every game! This is indicative of over-reacting and over-fitting to an individual game."
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#discussion",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#discussion",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Discussion",
    "text": "Discussion\nYou have now learned the basics behind the popular Elo rating system in sports, including the steps for implementing Elo ratings from scratch in R to measure NFL team strength. Furthermore, you have a basic understanding for how to assess the predictive performance of the ratings using Brier score and how this can be used to tune the choice the update factor \\(K\\). Although we only considered the ratings for the 2023-24 season, you could observe how ratings change across a larger dataset of games spanning the Patrick Mahomes’ era.\nHowever, there are a number of additional questions and considerations that we did not cover in this module such as:\n\nInitial Elo ratings: Rather than using 1500 as the initial values for every team, you could use a more informed starting point such as Neil Paine’s NFL Elo ratings which start at the beginning of the league history.\nNew season? New roster?: We just demonstrated Elo ratings within one season, but what do we do across multiple seasons? Do we simply just use the final rating from the previous season as the initial rating in the following season? But teams change rosters so we likely want to make some correction.\nScaling factor: We fixed the scaling factor to be 400 in this module, but we could also tune this quantity in the same manner as \\(K\\).\nWhat games matter in assessment?: Although we walked through assessing the performance Elo ratings performance with Brier scores, we treated every game equally in this calculation. What if we wanted to tune our Elo rating system to yield the most optimal predictions in the playoffs, and ignore performance in the first few weeks of the season?\nWhat about margin of victory?: We only considered win/loss in a binary manner, but the score differential in a game may be informative of team strength. There are extensions to handle margin of victory in Elo ratings, but details are beyond the scope of this module.\n\nWith these considerations in mind, you now have the capability in implement Elo ratings in practice across a variety of sports.\nYou may find these additional resources helpful:\n\nFor football fans, you can simulate NFL seasons using your Elo ratings with the nflseedR package.\nThe elo package in R provides convenient functions for computing Elo ratings, similar to the functions we defined above.\nAn overview of the popular Glicko rating system by statistician Mark Glickman that quantifies uncertainty about the ratings."
  },
  {
    "objectID": "by-statsds-topic.html",
    "href": "by-statsds-topic.html",
    "title": "Modules By Topic",
    "section": "",
    "text": "Exploring Justin Verlander’s pitch type by count\n\n\n\n\n\n\n\n2D categorical data\n\n\nchi-squared test\n\n\nmosaic plots\n\n\n\n\nAn introduction to 2D categorical data\n\n\n\n\n\n\nJul 9, 2024\n\n\nRon Yurko\n\n\n\n\n\n\n\n\nIntroduction to Elo ratings\n\n\n\n\n\n\n\nElo ratings\n\n\nBrier score\n\n\nprediction\n\n\n\n\nAn introduction to Elo ratings using NFL game outcomes.\n\n\n\n\n\n\nJul 9, 2024\n\n\nRon Yurko\n\n\n\n\n\n\n\n\nIntroduction to Elo ratings (INSTRUCTOR SOLUTIONS)\n\n\n\n\n\nAn introduction to Elo ratings using NFL game outcomes.\n\n\n\n\n\n\nRon Yurko\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "football/nfl-elo-ratings.html",
    "href": "football/nfl-elo-ratings.html",
    "title": "Introduction to Elo ratings",
    "section": "",
    "text": "Elo ratings are one of the most popular approaches for estimating player/team strength across a variety of sports. You can find a number of different sports examples maintained by sportswriter Neil Paine, as well as older versions that were featured in the popular website FiveThirtyEight. These dynamic ratings are adjusted for opponent strength and can be used for historical comparisons, such as who is the greatest tennis player of all time?, and for predicting outcomes. In this module you will learn the basics of Elo ratings in the context of measuring NFL team strength, walking through steps to implement and assess Elo ratings from scratch in R."
  },
  {
    "objectID": "football/nfl-elo-ratings.html#learning-objectives",
    "href": "football/nfl-elo-ratings.html#learning-objectives",
    "title": "Introduction to Elo ratings",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this module, you will be able to:\n\nCompute the expected outcome or predicted probability based on player/team ratings.\nUpdate ratings following the observed outcome of a match/game.\nImplement the complete Elo ratings framework in R for a full NFL season.\nAssess Elo rating predictions using Brier score.\nTune the update factor and other settings to yield more optimal predictions."
  },
  {
    "objectID": "football/nfl-elo-ratings.html#data",
    "href": "football/nfl-elo-ratings.html#data",
    "title": "Introduction to Elo ratings",
    "section": "Data",
    "text": "Data\nThe dataset and description are available at the SCORE Network Data Repository."
  },
  {
    "objectID": "football/nfl-elo-ratings.html#module-materials",
    "href": "football/nfl-elo-ratings.html#module-materials",
    "title": "Introduction to Elo ratings",
    "section": "Module Materials",
    "text": "Module Materials\n\n\n\n\n\n\nPrerequisites\n\n\n\nPrior to working on through this module, students are expected to know the following:\n\nFamiliar with R with the ability to read and write functions.\nSome exposure to predicting outcomes with probabilities.\n\nThe module has sections indicating which portions are challenging exercises, and is designed to take an undergraduate student roughly 3-4 hours to complete.\n\n\nStudent assignment qmd file\nView instructor solutions"
  },
  {
    "objectID": "baseball/verlander-pitchtype.html",
    "href": "baseball/verlander-pitchtype.html",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "",
    "text": "After nearly two full seasons due to injury, at the age of 39 Justin Verlander returned for the 2022 season to win the American League Cy Young award and World Series with the Houston Astros. Leading the league in a variety of statistics, Verlander dominated in his starts throughout the season. Pitch selection has played a key role into Verlander’s recent success with the Astros. Verlander throws four types of pitches (using MLB’s abbreviation): fastball (FF), slider (SL), curveball (CB), and changeup (CH). However, pitches are thrown in the context of an at-bat where the ball-strike count starts 0-0, and progresses until either the batter strikes out (reaches three strikes), is walked (reaches four balls), or is either hit-by-pitch or hits the ball in-play. As the count varies, pitchers often decide to favor certain pitches over others, e.g, with three balls (i.e., 3-X counts) the pitcher may favor throwing more accurate fastballs relative to out-of-the-zone offspeed pitches that are favored with two strikes (i.e., X-2 counts).\nAs defined above, pitch type and count are categorical variables. In this module, you will work with datasets of pitches thrown by Justin Verlander during both the 2019 (see 2019 Pitches tab) and 2022 season (see 2022 Pitches tab). You will learn about exploring, testing, and visualizing 2D categorical data to discover if there is a relationship between the count and the type of pitch Verlander throws."
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#learning-objectives",
    "href": "baseball/verlander-pitchtype.html#learning-objectives",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this module, you will be able to:\n\nCreate and assess different visualizations of 2D categorical data.\nConduct and interpret chi-squared tests of independence.\nCreate mosaic plots to assess relationship between two categorical variables."
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#data",
    "href": "baseball/verlander-pitchtype.html#data",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Data",
    "text": "Data\nThe dataset and description are available at the SCORE Network Data Repository."
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#module",
    "href": "baseball/verlander-pitchtype.html#module",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Module",
    "text": "Module\nThis module was created with ISLE: https://isle.stat.cmu.edu/SCORE/pitchtype/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CMU SCORE Module Preprint Repository",
    "section": "",
    "text": "This page contains module materials for the SCORE Network that were created by faculty and students from the Department of Statistics & Data Science at Carnegie Mellon University.\nThis preprint repository enables you to search for modules by either sport (along the left), or you can browse by statistics and data science topic.\nPlease note that these material have not yet completed the required pedagogical and industry peer reviews to become a published module on the SCORE Network. However, instructors are still welcome to use these materials if they are so inclined.\nThe development of the SCORE with Data network is funded by the National Science Foundation (award 2142705)."
  }
]