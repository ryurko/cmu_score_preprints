[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CMU SCORE Module Preprint Repository",
    "section": "",
    "text": "This page contains module materials for the SCORE Network that were created by faculty and students from the Department of Statistics & Data Science at Carnegie Mellon University.\nThis preprint repository enables you to search for modules by either sport (along the left), or you can browse by statistics and data science topic.\nPlease note that these material have not yet completed the required pedagogical and industry peer reviews to become a published module on the SCORE Network. However, instructors are still welcome to use these materials if they are so inclined.\nThe development of the SCORE with Data network is funded by the National Science Foundation (award 2142705)."
  },
  {
    "objectID": "baseball/verlander-pitchtype.html",
    "href": "baseball/verlander-pitchtype.html",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "",
    "text": "After nearly two full seasons due to injury, at the age of 39 Justin Verlander returned for the 2022 season to win the American League Cy Young award and World Series with the Houston Astros. Leading the league in a variety of statistics, Verlander dominated in his starts throughout the season. Pitch selection has played a key role into Verlander’s recent success with the Astros. Verlander throws four types of pitches (using MLB’s abbreviation): fastball (FF), slider (SL), curveball (CB), and changeup (CH). However, pitches are thrown in the context of an at-bat where the ball-strike count starts 0-0, and progresses until either the batter strikes out (reaches three strikes), is walked (reaches four balls), or is either hit-by-pitch or hits the ball in-play. As the count varies, pitchers often decide to favor certain pitches over others, e.g, with three balls (i.e., 3-X counts) the pitcher may favor throwing more accurate fastballs relative to out-of-the-zone offspeed pitches that are favored with two strikes (i.e., X-2 counts).\nAs defined above, pitch type and count are categorical variables. In this module, you will work with datasets of pitches thrown by Justin Verlander during both the 2019 (see 2019 Pitches tab) and 2022 season (see 2022 Pitches tab). You will learn about exploring, testing, and visualizing 2D categorical data to discover if there is a relationship between the count and the type of pitch Verlander throws.",
    "crumbs": [
      "Home",
      "Baseball",
      "Exploring Justin Verlander's pitch type by count"
    ]
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#motivation",
    "href": "baseball/verlander-pitchtype.html#motivation",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "",
    "text": "After nearly two full seasons due to injury, at the age of 39 Justin Verlander returned for the 2022 season to win the American League Cy Young award and World Series with the Houston Astros. Leading the league in a variety of statistics, Verlander dominated in his starts throughout the season. Pitch selection has played a key role into Verlander’s recent success with the Astros. Verlander throws four types of pitches (using MLB’s abbreviation): fastball (FF), slider (SL), curveball (CB), and changeup (CH). However, pitches are thrown in the context of an at-bat where the ball-strike count starts 0-0, and progresses until either the batter strikes out (reaches three strikes), is walked (reaches four balls), or is either hit-by-pitch or hits the ball in-play. As the count varies, pitchers often decide to favor certain pitches over others, e.g, with three balls (i.e., 3-X counts) the pitcher may favor throwing more accurate fastballs relative to out-of-the-zone offspeed pitches that are favored with two strikes (i.e., X-2 counts).\nAs defined above, pitch type and count are categorical variables. In this module, you will work with datasets of pitches thrown by Justin Verlander during both the 2019 (see 2019 Pitches tab) and 2022 season (see 2022 Pitches tab). You will learn about exploring, testing, and visualizing 2D categorical data to discover if there is a relationship between the count and the type of pitch Verlander throws.",
    "crumbs": [
      "Home",
      "Baseball",
      "Exploring Justin Verlander's pitch type by count"
    ]
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#learning-objectives",
    "href": "baseball/verlander-pitchtype.html#learning-objectives",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this module, you will be able to:\n\nCreate and assess different visualizations of 2D categorical data.\nConduct and interpret chi-squared tests of independence.\nCreate mosaic plots to assess relationship between two categorical variables.",
    "crumbs": [
      "Home",
      "Baseball",
      "Exploring Justin Verlander's pitch type by count"
    ]
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#data",
    "href": "baseball/verlander-pitchtype.html#data",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Data",
    "text": "Data\nThe dataset and description are available at the SCORE Network Data Repository.",
    "crumbs": [
      "Home",
      "Baseball",
      "Exploring Justin Verlander's pitch type by count"
    ]
  },
  {
    "objectID": "baseball/verlander-pitchtype.html#module",
    "href": "baseball/verlander-pitchtype.html#module",
    "title": "Exploring Justin Verlander’s pitch type by count",
    "section": "Module",
    "text": "Module\nThis module was created with ISLE: https://isle.stat.cmu.edu/SCORE/pitchtype/",
    "crumbs": [
      "Home",
      "Baseball",
      "Exploring Justin Verlander's pitch type by count"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "",
    "text": "The purpose of this module is to introduce the basics of Elo ratings in the context of measuring NFL team strengths. This file contains guided exercises demonstrating how to implement Elo ratings from scratch in R.\nWe’ll use a subset of the NFL Game Outcomes dataset available on the SCORE Sports Data Repository, only considering games during the 2023-24 season. The following code chunk reads in the larger dataset and filters down to only include games during the 2023-24 season:\n\n# Need to have the tidyverse installed prior to starting!\nlibrary(tidyverse)\n\nnfl_games &lt;- read_csv(\"https://data.scorenetwork.org/data/nfl_mahomes_era_games.csv\") |&gt;\n  filter(season == 2023)\n\nAs indicated in the overview page for the larger dataset, each row in the dataset corresponds to a single game played during the 2023-24 season:\n\nnfl_games\n\n# A tibble: 285 × 10\n   season game_id      game_type  week home_team away_team home_score away_score\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n 1   2023 2023_01_DET… REG           1 KC        DET               20         21\n 2   2023 2023_01_CAR… REG           1 ATL       CAR               24         10\n 3   2023 2023_01_HOU… REG           1 BAL       HOU               25          9\n 4   2023 2023_01_CIN… REG           1 CLE       CIN               24          3\n 5   2023 2023_01_JAX… REG           1 IND       JAX               21         31\n 6   2023 2023_01_TB_… REG           1 MIN       TB                17         20\n 7   2023 2023_01_TEN… REG           1 NO        TEN               16         15\n 8   2023 2023_01_SF_… REG           1 PIT       SF                 7         30\n 9   2023 2023_01_ARI… REG           1 WAS       ARI               20         16\n10   2023 2023_01_GB_… REG           1 CHI       GB                20         38\n# ℹ 275 more rows\n# ℹ 2 more variables: game_outcome &lt;dbl&gt;, score_diff &lt;dbl&gt;\n\n\nNote the game_type column indicates if the game was during the regular season (REG), or during the playoffs with the different values indicating the different playoff rounds:\n\ntable(nfl_games$game_type)\n\n\nCON DIV REG  SB  WC \n  2   4 272   1   6 \n\n\nThe week column just increases in the correct order, which will be convenient for implementing Elo ratings over the course of the NFL season.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#intro-and-data",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#intro-and-data",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "",
    "text": "The purpose of this module is to introduce the basics of Elo ratings in the context of measuring NFL team strengths. This file contains guided exercises demonstrating how to implement Elo ratings from scratch in R.\nWe’ll use a subset of the NFL Game Outcomes dataset available on the SCORE Sports Data Repository, only considering games during the 2023-24 season. The following code chunk reads in the larger dataset and filters down to only include games during the 2023-24 season:\n\n# Need to have the tidyverse installed prior to starting!\nlibrary(tidyverse)\n\nnfl_games &lt;- read_csv(\"https://data.scorenetwork.org/data/nfl_mahomes_era_games.csv\") |&gt;\n  filter(season == 2023)\n\nAs indicated in the overview page for the larger dataset, each row in the dataset corresponds to a single game played during the 2023-24 season:\n\nnfl_games\n\n# A tibble: 285 × 10\n   season game_id      game_type  week home_team away_team home_score away_score\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n 1   2023 2023_01_DET… REG           1 KC        DET               20         21\n 2   2023 2023_01_CAR… REG           1 ATL       CAR               24         10\n 3   2023 2023_01_HOU… REG           1 BAL       HOU               25          9\n 4   2023 2023_01_CIN… REG           1 CLE       CIN               24          3\n 5   2023 2023_01_JAX… REG           1 IND       JAX               21         31\n 6   2023 2023_01_TB_… REG           1 MIN       TB                17         20\n 7   2023 2023_01_TEN… REG           1 NO        TEN               16         15\n 8   2023 2023_01_SF_… REG           1 PIT       SF                 7         30\n 9   2023 2023_01_ARI… REG           1 WAS       ARI               20         16\n10   2023 2023_01_GB_… REG           1 CHI       GB                20         38\n# ℹ 275 more rows\n# ℹ 2 more variables: game_outcome &lt;dbl&gt;, score_diff &lt;dbl&gt;\n\n\nNote the game_type column indicates if the game was during the regular season (REG), or during the playoffs with the different values indicating the different playoff rounds:\n\ntable(nfl_games$game_type)\n\n\nCON DIV REG  SB  WC \n  2   4 272   1   6 \n\n\nThe week column just increases in the correct order, which will be convenient for implementing Elo ratings over the course of the NFL season.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#background-information",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#background-information",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Background Information",
    "text": "Background Information\nElo ratings were created by physicist Arpad Elo in the 1960s for rating chess players. The main idea behind Elo ratings is to create an exchange in rating points between players (or teams) after a match. The simplest version of this system was constructed to be a zero-sum rating, such that the winner gains x points while the same number of x points are subtracted from the loser’s rating. If the win was expected, the winner receives fewer points than if the win was unexpected (i.e., an upset) - where the expectation is set prior to the match. This system results in a dynamic rating that is adjusted for opponent quality.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#method-details",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#method-details",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Method Details",
    "text": "Method Details\nWe’re going to consider a simple version of Elo ratings in the context of measuring NFL team strength via a rating. Let the rating for the home team be \\(R_{\\text{home}}\\) and the away team rating be \\(R_{\\text{away}}\\). Then the expected score for the home team \\(E_{\\text{home}}\\) is calculated as:\n\\[\nE_{\\text{home}} = \\frac{1}{1+10^{\\left(R_{\\text{away}}-R_{\\text{home}}\\right) / 400}},\n\\]\nand the expected score for the away team \\(E_{\\text{away}}\\) is computed in a similar manner:\n\\[\nE_{\\text{away}} = \\frac{1}{1+10^{\\left(R_{\\text{home}}-R_{\\text{away}}\\right) / 400}}.\n\\] These expected scores represent the probability of winning1, e.g., \\(E_{\\text{home}}\\) represents the probability of winning for the home team.\nThe choice of 10 and 400 in the denominator may appear arbitrary at first, but they correspond to:\n\na logistic curve (thus bounded by 0 and 1) with base 10, and\na scaling factor of 400 which can be tuned to yield better predictions (discussed in more detail below).\n\nA more general representation of the expected score would replace the choice of 10 with some constant (e.g., \\(e\\)) and replace 400 with a tune-able quantity \\(d\\). For now though we will just use 10 and 400 since they are the original choices.\nWhile the above quantities represent the expectation of a game between teams with ratings \\(R_{\\text{home}}\\) and \\(R_{\\text{away}}\\), we need a step to update the ratings after observing the game outcome. We can update we update the ratings for the home team based on the observed score \\(S_{\\text{home}}\\):\n\\[\nR^{\\text{new}}_{\\text{home}} = R_{\\text{home}} + K \\cdot (S_{\\text{home}} - E_{\\text{home}})\n\\]\nThe observed score \\(S_{\\text{home}}\\) is based on the game outcome such that,\n\n\\(S_{\\text{home}} = 1\\) if the home team wins,\n\\(S_{\\text{home}} = 0.5\\) if it is a draw, or\n\\(S_{\\text{home}} = 0\\) if the home team loses.\n\nWe compute the updated rating for the away team \\(R^{\\text{new}}_{\\text{away}}\\) in a similar manner, by replacing home team quantities with those with respect to the away team.\nThe quantity \\(K\\) is known as the update factor, indicating the maximum number of Elo rating points a team gains from winning a single game (and how many points are subtracted if they lose). This is a tuning parameter, which ideally should be selected to yield optimal predictive performance.\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: Given the above equation for \\(R^{\\text{new}}_{\\text{home}}\\), what do you think will happen as you increase \\(K\\)? Does a single game cause a larger or smaller change on a team’s rating? Likewise, what do you think will happen if you decrease \\(K\\)? Describe what you expect to observe in 1-3 sentences.\nANSWER: The update factor \\(K\\) controls how sensitive the ratings should be to a single game outcome. A larger choice of \\(K\\) will lead to a larger change in a team’s rating following a single game, and likewise a smaller choice of \\(K\\) will lead to a smaller change in a team’s rating.\n\n\nAlthough the details are beyond the scope of this module, there is a relationship between this Elo ratings update formula with stochastic gradient descent for logistic regression.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#learn-by-doing",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#learn-by-doing",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Learn by Doing",
    "text": "Learn by Doing\nWe’ll now proceed to implement Elo ratings for NFL teams during the 2023-24 season in R.\n\nCalculating and Updating Ratings\nWe will start by creating two helper functions to compute the expected scores and updated ratings after a game.\n\n\n\n\n\n\nActive Exercise\n\n\n\nFirst, based on the above formulas for expected score, complete the function calc_expected_score that takes in as input a team_rating and opp_team_rating then returns the expected score for the team relative to the opp_team. For ease, your function should use the base 10 logistic curve and scaling factor of 400 as fixed quantities.\n\ncalc_expected_score &lt;- function(team_rating, opp_team_rating) {\n  1 / (1 + 10^((opp_team_rating - team_rating) / 400))\n}\n\nQUESTION: Using your function calc_expected_score, what is the expected score for a team with a rating of 1400 playing against an opposing team with a rating of 1600?\nANSWER:\n\ncalc_expected_score(1400, 1600)\n\n[1] 0.2402531\n\n\nThe expected score for the team is about 0.24, indicating that the team with a rating of 1400 has an estimated 24% chance of beating an opponent with a rating of 1600.\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nNext, complete the calc_new_rating function that takes in an initial team_rating, the observed_score and expected_score with respect to that team, along with a choice of the update_factor \\(K\\) to return the new rating. For now, we will just consider \\(K = 20\\) as the default choice.\n\ncalc_new_rating &lt;- function(team_rating, observed_score, expected_score,\n                            update_factor = 20) {\n  team_rating + update_factor * (observed_score - expected_score)\n}\n\nQUESTION: Using your functions calc_expected_score and calc_new_rating together, what is the new rating for team that had an initial rating of 1300 but beat an opponent with a rating of 1700? You should answer this question using \\(K = 20\\), and pass in the output of calc_expected_score to be the expected_score. How does the observed change in the team’s rating compare to the maximum number of points the rating can change by?\nANSWER:\n\ncalc_new_rating(1300, 1, calc_expected_score(1300, 1700))\n\n[1] 1318.182\n\n\nThe team’s rating improves to roughly 1318 after winning. Since the maximum number of possible points is \\(K = 20\\), this is indicative of how beating a team with a rating of 1700 was relatively unexpected and nearly earned the team the maximum possible 20 points.\n\n\n\n\nNFL Elo Ratings\nNow with the basics, let’s move on to perform these calculations over the entire season, updating a table to include each team’s Elo rating following every game. We can implement this using a for loop to proceed through each game in the nfl_games table, looking up each team’s previous ratings and performing the above calculations.\nPrior to beginning this loop, we will set-up a table initializing each team with a rating of 1500. This a naive approach since we likely have prior knowledge about each team’s strength before the start of the season, but we’ll discuss this in more detail at the end of the module. For now, we’ll use 1500 since it is a common choice for initializing Elo ratings. The code chunk below initializes this starting table of ratings beginning with an imaginary week 0:\n\nnfl_elo_ratings &lt;- tibble(team = unique(nfl_games$home_team),\n                          elo_rating = 1500,\n                          week = 0)\nnfl_elo_ratings\n\n# A tibble: 32 × 3\n   team  elo_rating  week\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 KC          1500     0\n 2 ATL         1500     0\n 3 BAL         1500     0\n 4 CLE         1500     0\n 5 IND         1500     0\n 6 MIN         1500     0\n 7 NO          1500     0\n 8 PIT         1500     0\n 9 WAS         1500     0\n10 CHI         1500     0\n# ℹ 22 more rows\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: The code chunk below outlines the for loop to be used in updating team ratings after every game during the 2023-24 season in the nfl_games dataset. Fill in the missing portions code marked by ??? using your above calc_expected_score and calc_new_rating functions. While this module does not cover all of the basics of tidyverse data wrangling, the code comments should help make the various steps clear.\nANSWER:\n\nfor (game_i in 1:nrow(nfl_games)) {\n   \n  # Grab the home and away teams in the current game:\n  home_team &lt;- nfl_games$home_team[game_i]\n  away_team &lt;- nfl_games$away_team[game_i]\n  # What was the observed score by the home team?\n  observed_home_score &lt;- nfl_games$game_outcome[game_i]\n  # Retain the week number for this game:\n  game_week &lt;- nfl_games$week[game_i]\n  \n  # What was each team's rating from their latest game in the\n  # current elo ratings table, starting with the home team:\n  home_rating &lt;- nfl_elo_ratings |&gt;\n    filter(team == home_team) |&gt;\n    # Sort in descending order\n    arrange(desc(week)) |&gt;\n    # Grab the latest game\n    slice(1) |&gt;\n    # Just return the elo rating\n    pull(elo_rating)\n  \n  # Same thing for away team\n  away_rating &lt;- nfl_elo_ratings |&gt;\n    filter(team == away_team) |&gt;\n    arrange(desc(week)) |&gt;\n    slice(1) |&gt;\n    pull(elo_rating)\n  \n  # Now get their new ratings, starting with the home team:\n  new_home_rating &lt;- calc_new_rating(home_rating, observed_home_score, \n                                     calc_expected_score(home_rating,\n                                                         away_rating))\n  # And repeating for the away team using the opposite input as home team:\n  new_away_rating &lt;- calc_new_rating(away_rating, 1 - observed_home_score, \n                                     calc_expected_score(away_rating,\n                                                         home_rating))\n  \n  # Set up a table containing the updated ratings for each team after the game\n  updated_ratings &lt;- tibble(team = c(home_team, away_team),\n                            elo_rating = c(new_home_rating, new_away_rating),\n                            # Store the week index of the game\n                            week = rep(game_week, 2))\n  \n  # Add each teams new ratings to the current elo ratings table by row binding:\n  nfl_elo_ratings &lt;- nfl_elo_ratings |&gt;\n    bind_rows(updated_ratings)\n  \n}\n\n\n\nAfter you run the completed for loop, you can view and inspect the ratings in different ways. For example, the following code chunk will return the final rating for each after the completion of the entire season of games:\n\nnfl_elo_ratings |&gt;\n  group_by(team) |&gt;\n  # Since some teams make the playoffs, need to find the rating \n  # for each team's final weeK:\n  summarize(final_rating = elo_rating[which.max(week)]) |&gt;\n  # Sort in descending order of the rating so the best team is first:\n  arrange(desc(final_rating))\n\n# A tibble: 32 × 2\n   team  final_rating\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 KC           1576.\n 2 BAL          1575.\n 3 SF           1564.\n 4 DET          1561.\n 5 BUF          1547.\n 6 DAL          1546.\n 7 CLE          1532.\n 8 HOU          1528.\n 9 MIA          1525.\n10 LA           1523.\n# ℹ 22 more rows\n\n\n\n\n\n\n\n\nBONUS: Expand To Visualize Ratings\n\n\n\n\n\nIt is often helpful to visualize how the team ratings are changing over time. While this module does not cover the details about the ggplot2 visualization library, the following code creates a line for each team:\n\nnfl_elo_ratings |&gt;\n  # Input the dataset into ggplot, mapping the week to the x-axis and\n  # the elo_rating to the y-axis, colored by team:\n  ggplot(aes(x = week, y = elo_rating, color = team)) +\n  geom_line() +\n  theme_bw() +\n  labs(x = \"Week\", y = \"Elo rating\",\n       title = \"NFL Elo ratings in 2023-24 season\")\n\n\n\n\n\n\n\n\nWhile we can observe ratings changing over the season for every team, this visualization is less than ideal. Instead one could take advantage of the team colors available using the load_teams function from the nflverse This is a little more involved, but here is example way to create a figure highlighting teams in each division separately (this requires installing the nflreadr, ggrepel, and cowplot packages:\n\nlibrary(nflreadr)\nnfl_team_colors &lt;- load_teams() |&gt;\n  dplyr::select(team_abbr, team_division, team_color)\n\n# Create a dataset that has each team's final Elo rating\nnfl_team_final &lt;- nfl_elo_ratings |&gt;\n  group_by(team) |&gt;\n  summarize(week = max(week),\n            elo_rating = elo_rating[which.max(week)],\n            .groups = \"drop\") |&gt;\n  inner_join(nfl_team_colors, by = c(\"team\" = \"team_abbr\")) |&gt;\n  arrange(desc(elo_rating))\n \n# Need ggrepel:\nlibrary(ggrepel)\ndivision_plots &lt;- \n  lapply(sort(unique(nfl_team_final$team_division)),\n         function(nfl_division) {                            \n             # Pull out the teams in the division\n             division_teams &lt;- nfl_team_final |&gt;\n               filter(team_division == nfl_division) |&gt;\n               mutate(team = fct_reorder(team, desc(elo_rating))) \n             \n             # Get the Elo ratings data just for these teams:\n             division_data &lt;- nfl_elo_ratings |&gt;\n               filter(team %in% division_teams$team) |&gt;\n               mutate(team = factor(team,\n                                    levels = levels(division_teams$team))) |&gt;\n               # Make text labels for them:\n               group_by(team) |&gt;\n               mutate(team_label = if_else(week == max(week),\n                                           as.character(team), \n                                           NA_character_)) |&gt;\n               ungroup()\n             \n             # Now make the full plot\n             nfl_elo_ratings |&gt;\n               # Plot all of the other teams as gray lines:\n               filter(!(team %in% division_teams$team)) |&gt;\n               ggplot(aes(x = week, y = elo_rating, group = team)) +\n               geom_line(color = \"gray\", alpha = 0.5) +\n               # But display the division teams with their colors:\n               geom_line(data = division_data,\n                         aes(x = week, y = elo_rating, group = team,\n                             color = team)) +\n               geom_label_repel(data = division_data,\n                                aes(label = team_label,\n                                    color = team), nudge_x = 1, na.rm = TRUE,\n                                direction = \"y\") +\n               scale_color_manual(values = division_teams$team_color,\n                                  guide = FALSE) +\n               theme_bw() +\n               labs(x = \"Week\", y = \"Elo rating\",\n                    title = paste0(\"Division: \", nfl_division)) \n         })\n# Display the grid of plots with cowplot!\nlibrary(cowplot)\nplot_grid(plotlist = division_plots, ncol = 2, align = \"hv\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssessing the Ratings\nThe result of the for loop from above provides us with a dataset that contains the rating for each team after every week. But how do we know if we can trust this approach for estimating team ratings? We can assess the predictive performance of the Elo ratings based on the estimated probabilities for every game given the team’s ratings entering the game.\n\n\n\n\n\n\nChallenge: Missing Team ratings\n\n\n\nTo demonstrate this, we will first need to fill in for missing weeks for teams due to bye weeks. You can see in the output from the table counts below that during certain weeks there are fewer than 32 teams with ratings (this is not a concern in the values post week 18 since that corresponds to playoffs):\n\ntable(nfl_elo_ratings$week)\n\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n32 32 32 32 32 28 30 26 32 28 28 28 32 26 30 32 32 32 32 12  8  4  2 \n\n\nThe follow code chunks fixes this issue by iterating over each possible week, and fills in missing week ratings with the last available rating. There are multiple ways to do this! The details of the code are not necessarily important for understanding how to assess the accuracy of Elo ratings but rather a practical concern with implementation. If you are not interested in how the code works, feel free to just run it for usage in the remaining steps.\n\n# First get a vector of the unique teams from the table:\nnfl_teams &lt;- unique(nfl_elo_ratings$team)\n\n# Now iterate over the weeks and decide how to grab the team ratings\ncomplete_nfl_elo_ratings &lt;- \n  map_dfr(unique(nfl_elo_ratings$week),\n          function(week_i) {\n            \n            # How many teams have ratings in the week?\n            covered_teams &lt;- nfl_elo_ratings |&gt;\n              filter(week == week_i) |&gt;\n              pull(team) |&gt;\n              unique()\n            \n            if (length(nfl_teams) == length(covered_teams)) {\n              # Just return the rows from the nfl_elo_ratings table:\n              nfl_elo_ratings |&gt;\n                filter(week == week_i)\n              \n            } else {\n              # Otherwise, we need to fill in the missing teams\n              # First get the latest ratings for every team prior to this week:\n              latest_ratings &lt;- nfl_elo_ratings |&gt;\n                filter(week &lt; week_i) |&gt;\n                group_by(team) |&gt;\n                summarize(elo_rating = elo_rating[which.max(week)],\n                          .groups = \"drop\") |&gt;\n                mutate(week = week_i)\n              \n              # Now gather the ratings for teams that are not missing this week:\n              week_ratings &lt;- nfl_elo_ratings |&gt;\n                filter(week == week_i)\n              \n              # Join together the missing ratings and return:\n              week_ratings |&gt;\n                bind_rows(filter(latest_ratings,\n                                 !(latest_ratings$team %in% week_ratings$team)))\n              \n            }\n\n          })\n\n# And this now fixes the previous problem:\ntable(complete_nfl_elo_ratings$week)\n\n\n 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 \n\n\n\n\nWe will now make two copies of the complete_nfl_elo_ratings table - one to use for home teams and another to use for away teams. The code chunk below initializes these copies, and also adds 1 to the week column to indicate which week to use team’s rating for when predicting:\n\nhome_elo_ratings &lt;- complete_nfl_elo_ratings |&gt;\n  mutate(week = week + 1) |&gt;\n  # Rename the team and elo_rating columns\n  rename(home_team = team,\n         home_elo_rating = elo_rating)\n\n# And repeat for away teams:\naway_elo_ratings &lt;- complete_nfl_elo_ratings |&gt;\n  mutate(week = week + 1) |&gt;\n  rename(away_team = team,\n         away_elo_rating = elo_rating)\n\nNext, we can join the ratings stored in these two tables to the nfl_games table to estimate the expected outcome with respect to the home team. The following code chunk demonstrates how to left_join the team ratings, and then compute the probability of winning for the home team:\n\nupd_nfl_games &lt;- nfl_games |&gt;\n  # First join home team by the team abbreviation and week\n  left_join(home_elo_ratings, by = c(\"home_team\", \"week\")) |&gt;\n  # Repeat for away team ratings:\n  left_join(away_elo_ratings, by = c(\"away_team\", \"week\")) |&gt;\n  # And now compute the expectation, home_win_prob:\n  mutate(home_win_prob = calc_expected_score(home_elo_rating,\n                                             away_elo_rating))\nupd_nfl_games\n\n# A tibble: 285 × 13\n   season game_id      game_type  week home_team away_team home_score away_score\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n 1   2023 2023_01_DET… REG           1 KC        DET               20         21\n 2   2023 2023_01_CAR… REG           1 ATL       CAR               24         10\n 3   2023 2023_01_HOU… REG           1 BAL       HOU               25          9\n 4   2023 2023_01_CIN… REG           1 CLE       CIN               24          3\n 5   2023 2023_01_JAX… REG           1 IND       JAX               21         31\n 6   2023 2023_01_TB_… REG           1 MIN       TB                17         20\n 7   2023 2023_01_TEN… REG           1 NO        TEN               16         15\n 8   2023 2023_01_SF_… REG           1 PIT       SF                 7         30\n 9   2023 2023_01_ARI… REG           1 WAS       ARI               20         16\n10   2023 2023_01_GB_… REG           1 CHI       GB                20         38\n# ℹ 275 more rows\n# ℹ 5 more variables: game_outcome &lt;dbl&gt;, score_diff &lt;dbl&gt;,\n#   home_elo_rating &lt;dbl&gt;, away_elo_rating &lt;dbl&gt;, home_win_prob &lt;dbl&gt;\n\n\nWe can now assess the use of the Elo rating system with the computed home_win_prob values relative to the observed game_outcome. While there are a number of ways to evaluate the performance of a probability estimate, in this module we will consider the use of the Brier score which is computed as the mean squared difference between the observed outcome and predicted probabilities. In the context of our Elo rating system notation, the Brier score is computed across \\(N\\) games as:\n\\[\n\\frac{1}{N} \\sum_{i = 1}^{N} (S_{\\text{home},i} - E_{\\text{home},i})^2\n\\] where the use of subscript \\(i\\) refers to the outcome and expectation for the home team in game \\(i\\).\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: Given the above formula for computing the Brier score, what do you think is a better indicator predictive accuracy: a lower or higher Brier score?\nANSWER: It is more optimal to achieve a lower Brier score as this indicates the predicted probabilities are closer to the observed outcome.\n\n\nWe will compute the Brier score using our NFL Elo ratings, and compare the performance to always using a 50/50 probability for every game, i.e., as if we never learned any information over the course of the season.\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: Compute and report the Brier score for both: (1) the Elo rating based home_win_prob and (2) as if you predicted the probability to be 0.5 for every game. Which approach performs better? Are you surprised by the outcome?\nANSWER:\nThe following code chunk computes the Brier score for both approaches:\n\nupd_nfl_games |&gt;\n  summarize(elo_brier_score = mean((game_outcome - home_win_prob)^2),\n            base_brier_score = mean((game_outcome - 0.5)^2))\n\n# A tibble: 1 × 2\n  elo_brier_score base_brier_score\n            &lt;dbl&gt;            &lt;dbl&gt;\n1           0.245             0.25\n\n\nWe can see that the Elo ratings based Brier score is slightly lower than the 50/50 baseline. This is not surprising and should be re-assuring! We learn information about teams over the course of the season and this leads to better performance in predicting game outcomes.\n\n\nAlthough you have just implemented and evaluated the use of Elo ratings in the context of NFL games, so far we have just considered an update factor of \\(K = 20\\). But is there a more optimal choice?\n\n\n\n\n\n\nChallenging Active Exercise\n\n\n\n\n\nQUESTION: You will now proceed to different choices for the update factor. Rather than tediously code the entire process from above multiple times, we will wrap up the code to compute the Brier score for a given choice of \\(K\\) inside a function compute_elo_brier_score. The code chunk in the ANSWER portion below provides you with a template to fill out, this function takes in both the nfl_games data and input for the update_factor \\(K\\). Once you have completed the function, compute and report the Brier score for \\(K =\\) 5, 20, 50, and 100 (your value for \\(K = 20\\) should match the previous output). Which choice of \\(K\\) yields the best Brier score?\nANSWER:\nThe following is the complete version of the template code:\n\ncompute_elo_brier_score &lt;- function(games_table, update_factor) {\n  # First initialize the ratings:\n  nfl_elo_ratings &lt;- tibble(team = unique(games_table$home_team),\n                            elo_rating = 1500,\n                            week = 0)\n  \n  # Loop through to construct the Elo ratings:\n  for (game_i in 1:nrow(games_table)) {\n    \n    # Grab the home and away teams in the current game:\n    home_team &lt;- games_table$home_team[game_i]\n    away_team &lt;- games_table$away_team[game_i]\n    # What was the observed score by the home team?\n    observed_home_score &lt;- games_table$game_outcome[game_i]\n    # Retain the week number for this game:\n    game_week &lt;- games_table$week[game_i]\n    \n    # What was each team's rating from their latest game in the\n    # current elo ratings table, starting with the home team:\n    home_rating &lt;- nfl_elo_ratings |&gt;\n      filter(team == home_team) |&gt;\n      # Sort in descending order\n      arrange(desc(week)) |&gt;\n      # Grab the latest game\n      slice(1) |&gt;\n      # Just return the elo rating\n      pull(elo_rating)\n    \n    # Same thing for away team\n    away_rating &lt;- nfl_elo_ratings |&gt;\n      filter(team == away_team) |&gt;\n      arrange(desc(week)) |&gt;\n      slice(1) |&gt;\n      pull(elo_rating)\n    \n    # Now get their new ratings, starting with the home team:\n    new_home_rating &lt;- calc_new_rating(home_rating, observed_home_score, \n                                       calc_expected_score(home_rating,\n                                                           away_rating),\n                                       update_factor)\n    # And repeating for the away team using the opposite input as home team:\n    new_away_rating &lt;- calc_new_rating(away_rating, 1 - observed_home_score, \n                                       calc_expected_score(away_rating,\n                                                           home_rating),\n                                       update_factor)\n    \n    # Set up a table containing the updated ratings for each team after the game\n    updated_ratings &lt;- tibble(team = c(home_team, away_team),\n                              elo_rating = c(new_home_rating, new_away_rating),\n                              # Store the week index of the game\n                              week = rep(game_week, 2))\n    \n    # Add each teams new ratings to the current elo ratings table by row binding:\n    nfl_elo_ratings &lt;- nfl_elo_ratings |&gt;\n      bind_rows(updated_ratings)\n    \n  }\n  \n  # Fill in the missing ratings for teams:\n  \n  # First get a vector of the unique teams from the table:\n  nfl_teams &lt;- unique(nfl_elo_ratings$team)\n  \n  # Now iterate over the weeks and decide how to grab the team ratings\n  complete_nfl_elo_ratings &lt;- \n    map_dfr(unique(nfl_elo_ratings$week),\n            function(week_i) {\n              \n              # How many teams have ratings in the week?\n              covered_teams &lt;- nfl_elo_ratings |&gt;\n                filter(week == week_i) |&gt;\n                pull(team) |&gt;\n                unique()\n              \n              if (length(nfl_teams) == length(covered_teams)) {\n                # Just return the rows from the nfl_elo_ratings table:\n                nfl_elo_ratings |&gt;\n                  filter(week == week_i)\n                \n              } else {\n                # Otherwise, we need to fill in the missing teams\n                # First get the latest ratings for every team prior to this week:\n                latest_ratings &lt;- nfl_elo_ratings |&gt;\n                  filter(week &lt; week_i) |&gt;\n                  group_by(team) |&gt;\n                  summarize(elo_rating = elo_rating[which.max(week)],\n                            .groups = \"drop\") |&gt;\n                  mutate(week = week_i)\n                \n                # Now gather the ratings for teams that are not missing this week:\n                week_ratings &lt;- nfl_elo_ratings |&gt;\n                  filter(week == week_i)\n                \n                # Join together the missing ratings and return:\n                week_ratings |&gt;\n                  bind_rows(filter(latest_ratings,\n                                   !(latest_ratings$team %in% week_ratings$team)))\n                \n              }\n              \n            })\n  \n  \n  # Join the home and away team ratings for every game to get the probabilities:\n  home_elo_ratings &lt;- complete_nfl_elo_ratings |&gt;\n    mutate(week = week + 1) |&gt;\n    # Rename the team and elo_rating columns\n    rename(home_team = team,\n           home_elo_rating = elo_rating)\n  \n  # And repeat for away teams:\n  away_elo_ratings &lt;- complete_nfl_elo_ratings |&gt;\n    mutate(week = week + 1) |&gt;\n    rename(away_team = team,\n           away_elo_rating = elo_rating)\n  \n  # Compute and return the Brier score\n  games_table |&gt;\n    # First join home team by the team abbreviation and week\n    left_join(home_elo_ratings, by = c(\"home_team\", \"week\")) |&gt;\n    # Repeat for away team ratings:\n    left_join(away_elo_ratings, by = c(\"away_team\", \"week\")) |&gt;\n    # And now compute the expectation, home_win_prob:\n    mutate(home_win_prob = calc_expected_score(home_elo_rating,\n                                               away_elo_rating)) |&gt;\n    summarize(brier_score = mean((game_outcome - home_win_prob)^2)) |&gt;\n    pull(brier_score)\n}\n\n# Return the Brier score across the values for K:\ncompute_elo_brier_score(nfl_games, 5)\n\n[1] 0.2478319\n\ncompute_elo_brier_score(nfl_games, 20)\n\n[1] 0.244792\n\ncompute_elo_brier_score(nfl_games, 50)\n\n[1] 0.2470157\n\ncompute_elo_brier_score(nfl_games, 100)\n\n[1] 0.258864\n\n\nAlthough the Brier score is close between 5, 20, and 50, we can see that 20 yields the lowest Brier score. Notably, \\(K = 100\\) yields a Brier score that is worse than guessing 50/50 for every game! This is indicative of over-reacting and over-fitting to an individual game.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#discussion",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#discussion",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Discussion",
    "text": "Discussion\nYou have now learned the basics behind the popular Elo rating system in sports, including the steps for implementing Elo ratings from scratch in R to measure NFL team strength. Furthermore, you have a basic understanding for how to assess the predictive performance of the ratings using Brier score and how this can be used to tune the choice the update factor \\(K\\). Although we only considered the ratings for the 2023-24 season, you could observe how ratings change across a larger dataset of games spanning the Patrick Mahomes’ era.\nHowever, there are a number of additional questions and considerations that we did not cover in this module such as:\n\nInitial Elo ratings: Rather than using 1500 as the initial values for every team, you could use a more informed starting point such as Neil Paine’s NFL Elo ratings which start at the beginning of the league history.\nNew season? New roster?: We just demonstrated Elo ratings within one season, but what do we do across multiple seasons? Do we simply just use the final rating from the previous season as the initial rating in the following season? But teams change rosters so we likely want to make some correction.\nScaling factor: We fixed the scaling factor to be 400 in this module, but we could also tune this quantity in the same manner as \\(K\\).\nWhat games matter in assessment?: Although we walked through assessing the performance Elo ratings performance with Brier scores, we treated every game equally in this calculation. What if we wanted to tune our Elo rating system to yield the most optimal predictions in the playoffs, and ignore performance in the first few weeks of the season?\nWhat about margin of victory?: We only considered win/loss in a binary manner, but the score differential in a game may be informative of team strength. There are extensions to handle margin of victory in Elo ratings, but details are beyond the scope of this module.\n\nWith these considerations in mind, you now have the capability in implement Elo ratings in practice across a variety of sports.\nYou may find these additional resources helpful:\n\nFor football fans, you can simulate NFL seasons using your Elo ratings with the nflseedR package.\nThe elo package in R provides convenient functions for computing Elo ratings, similar to the functions we defined above.\nAn overview of the popular Glicko rating system by statistician Mark Glickman that quantifies uncertainty about the ratings.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#footnotes",
    "href": "module_resources/nfl-elo-ratings/intro_elo_ratings_SOLUTIONS.html#footnotes",
    "title": "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically, it represents the probability of winning and half the probability of drawing, but for our purposes we will just treat this as the probability of winning due to how rare draws are in the NFL.↩︎",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nfl Elo Ratings",
      "Introduction to Elo ratings (INSTRUCTOR SOLUTIONS)"
    ]
  },
  {
    "objectID": "by-statsds-topic.html",
    "href": "by-statsds-topic.html",
    "title": "Modules By Topic",
    "section": "",
    "text": "Exploring Justin Verlander’s pitch type by count\n\n\n\n\n\n\n2D categorical data\n\n\nchi-squared test\n\n\nmosaic plots\n\n\n\nAn introduction to 2D categorical data \n\n\n\n\n\nJul 9, 2024\n\n\nRon Yurko\n\n\n\n\n\n\n\n\n\n\n\n\nINSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)\n\n\n\n\n\nAn introduction to ridge regression in the context of estimating basketball player effects. \n\n\n\n\n\nRon Yurko, Quang Nguyen\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Elo ratings\n\n\n\n\n\n\nElo ratings\n\n\nBrier score\n\n\nprediction\n\n\n\nAn introduction to Elo ratings using NFL game outcomes. \n\n\n\n\n\nJul 9, 2024\n\n\nRon Yurko\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Elo ratings (INSTRUCTOR SOLUTIONS)\n\n\n\n\n\nAn introduction to Elo ratings using NFL game outcomes. \n\n\n\n\n\nRon Yurko\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to regularized adjusted plus-minus (RAPM)\n\n\n\n\n\n\nridge regression\n\n\npenalized regression\n\n\nregularization\n\n\nlinear regression\n\n\nadjusted plus-minus\n\n\n\nAn introduction to ridge regression in the context of estimating basketball player effects. \n\n\n\n\n\nJul 16, 2024\n\n\nRon Yurko, Quang Nguyen\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Modules By Topic"
    ]
  },
  {
    "objectID": "basketball/nba-rapm.html",
    "href": "basketball/nba-rapm.html",
    "title": "Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "",
    "text": "Measuring a player’s effect on game outcomes is one of the most fundamental tasks in sports analytics. But this is not a simple thing to do, and varies greatly between sports! In the National Basketball Association (NBA), traditional box-score statistics provide a limited view of a player’s performance. In order to measure an individual player’s contribution, it is necessary to adjust for the presence of their teammates and opposition. Different versions of regularized adjusted plus-minus (RAPM) models are popular approaches in the basketball analytics community for attempting to address this challenge. In this module, you will build a RAPM model in R for NBA players in an attempt to estimate an individual player’s effect when on the court.",
    "crumbs": [
      "Home",
      "Basketball",
      "Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "basketball/nba-rapm.html#motivation",
    "href": "basketball/nba-rapm.html#motivation",
    "title": "Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "",
    "text": "Measuring a player’s effect on game outcomes is one of the most fundamental tasks in sports analytics. But this is not a simple thing to do, and varies greatly between sports! In the National Basketball Association (NBA), traditional box-score statistics provide a limited view of a player’s performance. In order to measure an individual player’s contribution, it is necessary to adjust for the presence of their teammates and opposition. Different versions of regularized adjusted plus-minus (RAPM) models are popular approaches in the basketball analytics community for attempting to address this challenge. In this module, you will build a RAPM model in R for NBA players in an attempt to estimate an individual player’s effect when on the court.",
    "crumbs": [
      "Home",
      "Basketball",
      "Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "basketball/nba-rapm.html#learning-objectives",
    "href": "basketball/nba-rapm.html#learning-objectives",
    "title": "Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this module, you will be able to:\n\nFit, interpret, and understand the limitations of adjusted plus-minus models.\nUnderstand the role of penalization in ridge regression.\nBecome familiar with basics of implementing ridge regression in R with glmnet.\nFit, interpret, and evaluate players using regularized adjusted plus-minus models.",
    "crumbs": [
      "Home",
      "Basketball",
      "Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "basketball/nba-rapm.html#data",
    "href": "basketball/nba-rapm.html#data",
    "title": "Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Data",
    "text": "Data\nThe dataset and description are available at the SCORE Network Data Repository.",
    "crumbs": [
      "Home",
      "Basketball",
      "Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "basketball/nba-rapm.html#module-materials",
    "href": "basketball/nba-rapm.html#module-materials",
    "title": "Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Module Materials",
    "text": "Module Materials\n\n\n\n\n\n\nPrerequisites\n\n\n\nPrior to working on through this module, students are expected to know the following:\n\nFamiliar with R and basic tidyverse data wrangling functions.\nExposure to linear regression.\nFamiliar with cross-validation.\n\nThe module has sections indicating which portions are challenging exercises, and is designed to take an undergraduate student roughly 3-4 hours to complete.\n\n\nStudent assignment qmd file\nView instructor solutions",
    "crumbs": [
      "Home",
      "Basketball",
      "Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html",
    "href": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html",
    "title": "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "",
    "text": "The purpose of this module is to walk through the basics of building a regularized adjusted plus-minus (RAPM) model to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents.\nWe’ll use NBA data available on the SCORE Network Data repository, that was already constructed for the purpose of building and comparing different approaches for estimating player effects. The data were gathered using the hoopR package, you can find the script for initializing the data on GitHub.\nThe following code chunk reads in a dataset that is in a wide form (discussed in detail below) with indicator columns for every player that was observed during the 2022-23 regular season:\n\n# Need to have the tidyverse installed prior to starting!\nlibrary(tidyverse)\nnba_rapm_data &lt;- read_csv(\"https://data.scorenetwork.org/data/nba_2223_season_rapm_data.csv.gz\")\n\nIn this dataset, we have 32,358 unique shifts/stints with 539 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100\n\n\n\nSince the above dataset does not include player names, only unique identifiers, we will also load in a table that includes player names to join over with the eventual results of the analysis. You can use the code chunk below to read in this table from the SCORE Network Data repository:\n\nnba_player_table &lt;- read_csv(\"https://data.scorenetwork.org/data/nba_2223_player_table.csv\")\n\nRows: 539 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player_name\ndbl (1): player_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnba_player_table\n\n# A tibble: 539 × 2\n   player_id player_name             \n       &lt;dbl&gt; &lt;chr&gt;                   \n 1   1630173 Precious Achiuwa        \n 2    203500 Steven Adams            \n 3   1628389 Bam Adebayo             \n 4   1630534 Ochai Agbaji            \n 5   1630583 Santi Aldama            \n 6   1629638 Nickeil Alexander-Walker\n 7   1628960 Grayson Allen           \n 8   1628386 Jarrett Allen           \n 9   1630631 Jose Alvarado           \n10    203937 Kyle Anderson           \n# ℹ 529 more rows",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nba Rapm",
      "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#intro-and-data",
    "href": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#intro-and-data",
    "title": "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "",
    "text": "The purpose of this module is to walk through the basics of building a regularized adjusted plus-minus (RAPM) model to estimate the impact of basketball players when they are on the court, while adjusting for the quality of their teammates and opponents.\nWe’ll use NBA data available on the SCORE Network Data repository, that was already constructed for the purpose of building and comparing different approaches for estimating player effects. The data were gathered using the hoopR package, you can find the script for initializing the data on GitHub.\nThe following code chunk reads in a dataset that is in a wide form (discussed in detail below) with indicator columns for every player that was observed during the 2022-23 regular season:\n\n# Need to have the tidyverse installed prior to starting!\nlibrary(tidyverse)\nnba_rapm_data &lt;- read_csv(\"https://data.scorenetwork.org/data/nba_2223_season_rapm_data.csv.gz\")\n\nIn this dataset, we have 32,358 unique shifts/stints with 539 players represented by the indicator variables (+1 if on court for home team, -1 if on court for away team, and 0 if not on court). Additional context is captured by the following variables:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ngame_id\nUnique game ID\n\n\nstint_id\nUnique identifier within a game for a stint for particular combination of home and away lineup (in appearance of order, where 1 is the first stint in the game)\n\n\nn_pos\nNumber of possessions (combined for both home and away) during the observed stint\n\n\nhome_points\nNumber of points scored by the home team during the stint\n\n\naway_points\nNumber of points scored by the away team during the stint\n\n\nminutes\nLength of the stint in terms of minutes played\n\n\nmargin\nCommon response for RAPM models defined as: (home_points - away_points) / n_pos * 100\n\n\n\nSince the above dataset does not include player names, only unique identifiers, we will also load in a table that includes player names to join over with the eventual results of the analysis. You can use the code chunk below to read in this table from the SCORE Network Data repository:\n\nnba_player_table &lt;- read_csv(\"https://data.scorenetwork.org/data/nba_2223_player_table.csv\")\n\nRows: 539 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): player_name\ndbl (1): player_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnba_player_table\n\n# A tibble: 539 × 2\n   player_id player_name             \n       &lt;dbl&gt; &lt;chr&gt;                   \n 1   1630173 Precious Achiuwa        \n 2    203500 Steven Adams            \n 3   1628389 Bam Adebayo             \n 4   1630534 Ochai Agbaji            \n 5   1630583 Santi Aldama            \n 6   1629638 Nickeil Alexander-Walker\n 7   1628960 Grayson Allen           \n 8   1628386 Jarrett Allen           \n 9   1630631 Jose Alvarado           \n10    203937 Kyle Anderson           \n# ℹ 529 more rows",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nba Rapm",
      "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#background-information",
    "href": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#background-information",
    "title": "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Background Information",
    "text": "Background Information\nMeasuring a player’s effect on game outcomes is one of the most fundamental tasks in sports analytics. But this is not a simple thing to do, and varies greatly between sports! In sports like basketball and hockey, a popular starting point for measuring a player’s impact is Plus-Minus which is defind as:\n\nPlus-Minus = points scored by team when player is on court - points scored by opposing team when player is on court\n\nYou can find leaderboards for this statistic on the NBA stats website.\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: What do you think are potential limitations with the above Plus-Minus statistic?\nANSWER: The naive version of Plus-Minus ignores the influence of a player’s teammates and the opponents they faced during their time on the court. If a “bad” player shares court with a “good” player, they may have a strong positive Plus-Minus since their “good” teammate can offset the “bad” player (and vice versa). Likewise, if a “good” player has a more difficult schedule against stronger opponents then it can potentially hurt their Plus-Minus (with the opposite true against an easier schedule of weaker opponents).\n\n\nWe’ll now walk through how to improve on Plus-Minus with regression-based approaches using the NBA data loaded in the beginning of the module.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nba Rapm",
      "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#learn-by-doing",
    "href": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#learn-by-doing",
    "title": "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Learn By Doing",
    "text": "Learn By Doing\n\nAdjusted Plus-Minus (APM)\nIntroduced by Rosenbaum (2004), adjusted Plus-Minus (APM) is a regression-based approach to estimate a player’s impact on game outcomes while accounting for their teammates and opponents. How does this work? APM is a regression model where the predictors are indicator variable for every player denoting if they are on the court. The response variable is some type of outcome observed as the possession or shift-level (explained below). To be more explicit:\n\nThere are 10 players on the court at a time during a basketball game, 5 on side and 5 on the other.\nA basketball game has \\(T\\) shifts (or stints) that are periods of time without substitutions (i.e., there are no changes to who are playing on the court).\nWe will consider each 10-person shift \\(t = 1,\\dots,T\\) to be a single observation.\nThe reponse variable is some type of game outcome measure, such as the score differential during shift \\(t\\) from the view of the home team (i.e., home team score - away team score).\nThe predictor variables represented in the \\(T \\times p\\) design matrix \\(X\\) are columns for each of the \\(p\\) players in the league, such that:\n\n\\(X_{tj} = 1\\) if player \\(j\\) is on the court for the home team during shift \\(t\\)\n\\(X_{tj} = -1\\) if player \\(j\\) is on the court for the away team during shift \\(t\\)\n\\(X_{tj} = 0\\) if player \\(j\\) is not on the court during shift \\(t\\)\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are a number of different ways to set-up the APM design matrix \\(X\\), but we will only consider this design based on home and away team status in this module.\n\n\nAs discussed at the beginning of this module, the nba_rapm_data you loaded contains these player indicator variables. The code chunk below prints the first so many rows of this dataset:\n\nnba_rapm_data\n\n# A tibble: 32,358 × 546\n   game_id    stint_id n_pos home_points away_points minutes margin `201939`\n   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n 1 0022200002        1    14           5           2   2.7     21.4        1\n 2 0022200002        2     9           6           2   1.67    44.4        1\n 3 0022200002        3     5           0           3   0.480  -60          1\n 4 0022200002        4     5           5           1   0.78    80          1\n 5 0022200002        5     9           3           6   1.52   -33.3        1\n 6 0022200002        6     8           0           6   1.45   -75          1\n 7 0022200002        7     5           0           0   0.800    0          0\n 8 0022200002        8     5           1           0   0.9     20          0\n 9 0022200002        9     3           2           0   0.97    66.7        0\n10 0022200002       10     7           2           2   1.66     0          1\n# ℹ 32,348 more rows\n# ℹ 538 more variables: `202691` &lt;dbl&gt;, `203110` &lt;dbl&gt;, `203952` &lt;dbl&gt;,\n#   `1626172` &lt;dbl&gt;, `1629673` &lt;dbl&gt;, `203210` &lt;dbl&gt;, `1630164` &lt;dbl&gt;,\n#   `1630228` &lt;dbl&gt;, `1628978` &lt;dbl&gt;, `1630541` &lt;dbl&gt;, `1631157` &lt;dbl&gt;,\n#   `201143` &lt;dbl&gt;, `203935` &lt;dbl&gt;, `1627759` &lt;dbl&gt;, `1628369` &lt;dbl&gt;,\n#   `1628401` &lt;dbl&gt;, `203943` &lt;dbl&gt;, `1629684` &lt;dbl&gt;, `1627763` &lt;dbl&gt;,\n#   `201933` &lt;dbl&gt;, `1630573` &lt;dbl&gt;, `101108` &lt;dbl&gt;, `1626164` &lt;dbl&gt;, …\n\n\nThe Rosenbaum (2004) implementation of APM relies on weighted least squares, where you solve for the \\(p\\)-dimensional vector of player coefficients \\(\\boldsymbol{\\beta}\\) using a modified version of the traditional least squares model:\n\\[\n\\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol{\\beta} \\in \\mathbb{R}^p}{\\text{arg min}} \\sum_{t = 1}^T n_t (y_t - X_t \\boldsymbol{\\beta})^2\n\\] * \\(y_t\\) is the response variable during shift \\(t\\), * \\(X_t\\) is the row of the design matrix for shift \\(t\\), and * \\(n_t\\) is the number possessions during shift \\(t\\).\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: What do you think is the motivation behind using weighted least squares rather than ordinary least squares without weights? Think about the choice of using the number of possessions as the weights.\nANSWER: Since a shift of time can vary in length, the idea behind using the number of possessions as weights is to place more importance on observations that effectively capture more periods of game play. Observed shifts with more possessions should be more informative about player performance than shifts with fewer possessions.\n\n\nWe’ll now work through fitting and intepreting the APM model in the context of NBA 2022-23 regular season data.\nFirst, compute the score differential as score_diff = home_points - away_points using mutate(). Append this new column to the nba_rapm_data dataset.\n\nnba_rapm_data &lt;- nba_rapm_data |&gt;\n  mutate(score_diff = home_points - away_points)\n\nNext, create a new dataset named nba_apm_model_data that contains only the response score_diff and the player columns:\n\nnba_apm_model_data &lt;- nba_rapm_data |&gt;\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,\n                   margin))\n\nNext, fit the model using the code below:\n\nrosenbaum_model &lt;- lm(score_diff ~ 0 + ., data = nba_apm_model_data,\n                      weights = nba_rapm_data$n_pos)\n\n\n\n\n\n\n\nNote\n\n\n\nCompared to fitting a linear regression model in R using the lm() with a small number of predictors, this model has the following aspects:\n\nThe intercept term is not included by specifying 0 at the beginning of the formula,\nUsing + . in the formula tells lm() to use every column in the data as predictors,\nweights = nba_rapm_data$n_pos ensures that we are using weighted least squares with the n_pos column (number of possessions during the shift) as the weights.\n\n\n\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: Why is it appropriate to remove the intercept term in the above regression model?\nANSWER: We need to remove the intercept term in the APM because it is impossible for every column of \\(X\\) to be 0, i.e., we will always observe 10 columns to have non-zero values in every single row of the dataset. This means the intercept term is nonsensical and should be removed from model fitting.\n\n\nWe’re not going to view the summary of this model since it is a bit of a mess (there are many player variables!). Instead, we’ll take advantage of the broom package to view the coefficients. The code chunk below demonstrates how to use the broom package to tidy up the output so that one row of the rosenbaum_coef table corresponds to a single player coefficient with information you would observe from the summary() output such as the coefficient estimate (estimate), standard error (std.error), \\(t\\)-statistic (statistic), \\(p\\)-value (p.value):\n\nlibrary(broom)\nrosenbaum_coef &lt;- tidy(rosenbaum_model)\nrosenbaum_coef\n\n# A tibble: 539 × 5\n   term      estimate std.error statistic p.value\n   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1 `201939`   -0.303       1.58   -0.192    0.848\n 2 `202691`   -1.01        1.58   -0.641    0.521\n 3 `203110`    0.214       1.58    0.135    0.892\n 4 `203952`    0.0336      1.58    0.0213   0.983\n 5 `1626172`  -0.417       1.58   -0.265    0.791\n 6 `1629673`  -1.36        1.57   -0.866    0.386\n 7 `203210`   -0.971       1.58   -0.613    0.540\n 8 `1630164`  -1.02        1.59   -0.640    0.522\n 9 `1630228`  -0.663       1.58   -0.421    0.674\n10 `1628978`  -0.565       1.57   -0.359    0.720\n# ℹ 529 more rows\n\n\nIn this current form, we have no idea which player is which since the term column contains the unique ID for each player. However, we can take advantage of the previously loaded nba_player_table (which has the same number of rows as rosenbaum_coef) to join over the player names to the rosenbaum_coef table.\nWe first need to modify the term column by removing the back-tick symbols and then convert the IDs to numeric values before joining over the player names. The code chunk below performs these steps, using the left_join() function by matching the two tables on the term and player_id columns:\n\nrosenbaum_coef &lt;- rosenbaum_coef |&gt;\n  # First convert the term column to numeric:\n  mutate(term = as.numeric(str_remove_all(term, \"`\"))) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\nrosenbaum_coef\n\n# A tibble: 539 × 6\n      term estimate std.error statistic p.value player_name     \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1  201939  -0.303       1.58   -0.192    0.848 Stephen Curry   \n 2  202691  -1.01        1.58   -0.641    0.521 Klay Thompson   \n 3  203110   0.214       1.58    0.135    0.892 Draymond Green  \n 4  203952   0.0336      1.58    0.0213   0.983 Andrew Wiggins  \n 5 1626172  -0.417       1.58   -0.265    0.791 Kevon Looney    \n 6 1629673  -1.36        1.57   -0.866    0.386 Jordan Poole    \n 7  203210  -0.971       1.58   -0.613    0.540 JaMychal Green  \n 8 1630164  -1.02        1.59   -0.640    0.522 James Wiseman   \n 9 1630228  -0.663       1.58   -0.421    0.674 Jonathan Kuminga\n10 1628978  -0.565       1.57   -0.359    0.720 Donte DiVincenzo\n# ℹ 529 more rows\n\n\nNow with the player names joined, let’s examine which players are the top 10 and bottom 10 in terms of their reported APM coefficients. You could easily view the top 10 players with the slice_max() function as demonstrated in the code chunk below:\n\nrosenbaum_coef |&gt;\n  slice_max(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name     \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1 1629735     5.72      2.66     2.15   0.0314 Chris Silva     \n 2 1631495     4.82      3.41     1.41   0.157  Donovan Williams\n 3 1630648     4.04      3.26     1.24   0.215  Jordan Schakel  \n 4 1629126     2.71      2.83     0.960  0.337  Deonte Burton   \n 5 1630600     2.71      1.86     1.46   0.145  Isaiah Mobley   \n 6 1629714     2.45      1.94     1.27   0.205  Jarrell Brantley\n 7 1641645     2.03      1.82     1.11   0.265  Xavier Cooks    \n 8 1630649     1.92      4.61     0.417  0.677  Stanley Umude   \n 9 1630644     1.40      2.11     0.664  0.507  Mac McClung     \n10 1628371     1.33      1.65     0.810  0.418  Jonathan Isaac  \n\n\nAnd similarly use slice_min() to display the bottom 10:\n\nrosenbaum_coef |&gt;\n  slice_min(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name    \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n 1 1631211    -8.43      2.65     -3.19 0.00144 Trevor Keels   \n 2 1630241    -5.95      1.91     -3.12 0.00181 Sam Merrill    \n 3 1628435    -5.26      2.24     -2.35 0.0190  Chance Comanche\n 4 1630225    -3.93      1.92     -2.04 0.0410  Isaiah Todd    \n 5 1630206    -3.80      2.08     -1.83 0.0672  Jay Scrubb     \n 6 1628382    -3.58      1.73     -2.07 0.0381  Justin Jackson \n 7 1631157    -3.29      1.75     -1.88 0.0607  Ryan Rollins   \n 8 1631311    -3.02      2.31     -1.31 0.191   Lester Quinones\n 9 1631320    -3.00      2.67     -1.12 0.261   Chima Moneke   \n10 1630643    -2.90      1.84     -1.58 0.115   Jay Huff       \n\n\nThese look like pretty extreme values, with the most extreme values observed by players that have limited playing time (upon searching their stats online). Before we think about how to address these issues, let’s look at what happens if we make a slight tweak to our model by using the margin variable as the response instead which is defined as:\n\nmargin = (home_points - away_points) / n_pos * 100\n\nThis response is often preferred in the basketball analytics community, as it places the response on a scale of points per 100 possessions (which is comparable to the number of possessions in each basketball game).\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION:\nRepeat the steps from above, but fit a new regression model using the margin variable in the original data nba_rapm_data as the response instead of score_diff. Do NOT include any weights since the number of possessions is already accounted for in margin. Report the top 10 players based on this new APM model with margin. How do the rankings and estimates compare to the Rosenbaum APM model from above?\nANSWER:\n\n# Now for ease, create a dataset that only has the response and player columns:\nnba_margin_apm_model_data &lt;- nba_rapm_data |&gt;\n  dplyr::select(-c(game_id, stint_id, n_pos, home_points, away_points, minutes,\n                   score_diff))\n\n# Fit the model (notice we do not include an intercept term)\nrosenbaum_margin_model &lt;- lm(margin ~ 0 + ., data = nba_margin_apm_model_data)\n\n# Get the coefficients and join player names:\nrosenbaum_margin_coef &lt;- tidy(rosenbaum_margin_model) |&gt;\n  # First convert the term column to numeric:\n  mutate(term = as.numeric(str_remove_all(term, \"`\"))) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\n\n# View top 10:\nrosenbaum_margin_coef |&gt;\n  slice_max(estimate, n = 10)\n\n# A tibble: 10 × 6\n      term estimate std.error statistic p.value player_name     \n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1 1630649     75.4      52.0     1.45    0.147 Stanley Umude   \n 2 1630648     60.6      53.1     1.14    0.253 Jordan Schakel  \n 3 1628993     49.1      31.5     1.56    0.119 Alize Johnson   \n 4 1630250     49.1      36.4     1.35    0.177 Marko Simonovic \n 5 1629126     45.4      51.2     0.888   0.375 Deonte Burton   \n 6 1631495     45.1      60.3     0.748   0.455 Donovan Williams\n 7 1630600     40.1      31.7     1.27    0.205 Isaiah Mobley   \n 8  203999     36.2      27.5     1.32    0.187 Nikola Jokic    \n 9 1628973     35.6      27.4     1.30    0.193 Jalen Brunson   \n10 1631112     35.1      30.7     1.14    0.253 Kendall Brown   \n\n\nWe start to see names that make sense, like Nikola Jokic who was one of the best players in the NBA during the 2022-23 season. We also notice the difference in magnitude now for the coefficient estimates compared to the previous score differential model. This is because the response is on the scale of points per 100 possessions.\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: Using the results of your margin-based model. Create a visualization displaying the distribution of the player coefficients. Describe what you observe about this distribution.\nANSWER:\n\nrosenbaum_margin_coef |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  labs(x = \"APM estimate\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can see that the coefficient distribution is roughly normal looking! We observe that most players display coefficients within a reasonable range but we do see some extreme looking values on the tail ends. This motivates the role of thinking about a group-level distribution for which player coefficients may come from.\n\n\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: What do you think are potential issues and concerns with the APM model?\nANSWER: There are number of different concerns regarding the APM model:\n\nHigh-dimensional problem: There are hundreds of player coefficients to estimate in the model. This is a high-dimensional regression problem, thus meaning that we need sufficient amount of data to estimate appropriately.\nMulticollinearity: Players are often substituted in and out simultaneously, or for one another - without adjustments. This will lead to collinearity between player columns, which can result in larger variance for the player coefficients, as well as decreases the precision of estimates. The challenge of multicollinearity makes it more difficult to parse between which players deserve more credit.\nLimited playing time: For players with limited playing time, we may observe unstable and extreme coefficient values. There are different ways to address this (such as the way we’ll handle it in RAPM), but one option in APM is to replace all players with limited playing time as single column, i.e., replacement-level player.\n\n\n\n\n\nRegularized Adjusted Plus-Minus (RAPM)\nNext, we’ll address some of the common issues facing APM models using Regularized Adjusted Plus-Minus (RAPM). The first public instance of RAPM for basketball was by Joe Sill (2010) in an award winning research paper at a sports analytics conference. This version of RAPM relies on ridge regression to apply a penalty term for shrinking player coefficients. More specifically, we can update the previous formula for estimating player coefficients as follows:\n\\[\n\\hat{\\boldsymbol{\\beta}}^{ridge} = \\underset{\\boldsymbol{\\beta} \\in \\mathbb{R}^p}{\\text{arg min}} \\sum_{t = 1}^T (y_t - X_t \\boldsymbol{\\beta})^2 + \\lambda \\sum_{j = 1}^p \\beta_p^2\n\\]\nThis objective for the ridge regression coefficients is effectively the combination of the loss (the traditional least squares objective) and newly included penalty term (the sum of the squared coefficient values). The ridge regression coefficients are solved for while balancing these two terms simultaneously, with the amount penalization controlled by \\(\\lambda\\). We can consider \\(\\lambda\\) to be a tuning parameter that controls the strength of the penalty term, and we will want to choose the \\(\\lambda\\) based on out-of-sample performance.\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: What happens to the coefficients if \\(\\lambda = 0\\)? What happens to the coefficients as \\(\\lambda \\rightarrow + \\infty\\)?\nANSWER:\n\nIf \\(\\lambda = 0\\): we just observe the same coefficients from fitting ordinary least squares, with no penalty term included.\nAs \\(\\lambda \\rightarrow + \\infty\\): the coefficients shrink towards 0, but never actually equal zero.\n\n\n\n\n\n\n\n\n\nChallenging Exercise\n\n\n\n\n\nQUESTION: Ignoring the context of RAPM models, suppose you regress a response variable \\(Y\\) on two variables \\(X_1\\) and \\(X_2\\) where \\(X_1 = X_2\\). What is the solution to ridge regression in this case? Do you think this behavior is ideal in the context of estimating player effects in the presence of collinearity?\nANSWER:\nIf we plug in the two variables in the ridge regression objective function from above, and use the Euclidean norm notation of the squared terms, then the loss and penalty terms become:\n\\[\n|| Y - X_1 \\beta_1 - X_2 \\beta_2 ||_2^2 + \\lambda \\beta_1^2 + \\lambda \\beta_2^2\n\\] And since \\(X_1 = X_2\\), we can set \\(X = X_1 = X_2\\) so that this becomes:\n\\[\n|| Y - X (\\beta_1 + \\beta_2) ||_2^2 + \\lambda (\\beta_1^2 + \\beta_2^2)\n\\] Due to the quadratic constraint from \\(\\lambda (\\beta_1^2 + \\beta_2^2)\\), the unique solution to this objective is to set \\(\\beta_1 = \\beta_2\\)! Thus when two variables are perfectly equal to each other, they will receive equal coefficients in ridge regression.\nIn the context of modeling player effects in sports, this can be useful because it is signaling that we do not know how to distinguish two players from each other if we only ever observed them together - so the resulting coefficients will treat them as equal. However, the downside is that we likely have prior knowledge about the players and could benefit from including that somehow. Incorporating priors into RAPM models via Bayesian regression is beyond the scope of this module.\n\n\n\nWe’ll now walk through how to fit a RAPM model using ridge regression. The most popular implementation of fitting ridge regression (and other common penalized regression models) in R is with the glmnet package.\nFirst, grab only the player columns (i.e. the indicator variables in the original data), then convert to a matrix using as.matrix(), and store this as a new object named player_matrix.\n\nplayer_matrix &lt;- nba_margin_apm_model_data |&gt;\n  dplyr::select(-margin) |&gt;\n  as.matrix()\n\nNext, the code chunk below performs 10 fold cross-validation to fit a ridge regression model using glmnet. The function cv.glmnet is used to perform the 10 fold cross-validation, evaluating the out-of-sample performance for a grid of \\(\\lambda\\) values. Fill in the missing code below using the above player_matrix as the predictors with the margin variable as the response:\n\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.2.3\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n# View help for function with:\n# help(cv.glmnet)\n\n# ridge with 10 fold cv, no intercept and no standardization\nfit_ridge_cv &lt;- cv.glmnet(x = player_matrix,\n                          y = nba_margin_apm_model_data$margin,\n                          alpha = 0,\n                          intercept = FALSE,\n                          standardize = FALSE)\n\nThe following plot prints out the penalty selection for this model, with the choices for \\(\\lambda\\) displayed along the x-axis and the 10 fold cross-validation mean squared error displayed along the y-axis. The red points denote the average error across the 10 folds, with gray standard error intervals.\n\nplot(fit_ridge_cv)\n\n\n\n\n\n\n\n\nThe first vertical dashed line corresponds to the choice of \\(\\lambda\\) with the smallest average error across the 10 folds. The far right dashed line indicates the largest \\(\\lambda\\) that is within one standard error of the minimum error \\(\\lambda\\). Using this \\(\\lambda\\) value is often referred to as the “one-standard error rule” as it implies picking a more “conservative” model with more penalized coefficients. In this case, we will prefer to choose the minimum error \\(\\lambda\\) indicated with the first vertical dashed line.\n\n\n\n\n\n\nThought Exercise\n\n\n\nQUESTION: What do you think the implication is that all of the red points are within the gray standard error intervals for all possible \\(\\lambda\\) values?\nANSWER: This signals that in terms of out-of-sample performance, all of the choices of \\(\\lambda\\) are fairly similar, indicating large uncertainty about the model’s predictive performance. However, we are primarily interested in estimating player effects with RAPM and not necessarily concerned with the model’s predictive performance.\n\n\nWe can easily plot the path of the ridge regression shrinkage, to see how the coefficients are pulled towards 0 as the penalty increases. The following code chunk shows this full path:\n\nplot(fit_ridge_cv$glmnet.fit, xvar = \"lambda\")\n\n\n\n\n\n\n\n\nSimilar to the APM model analyis, we can again use the the broom package to make a tidy table of the coefficients for each player:\n\ntidy_ridge_coef &lt;- tidy(fit_ridge_cv$glmnet.fit)\ntidy_ridge_coef\n\n# A tibble: 53,900 × 5\n   term    step estimate lambda dev.ratio\n   &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n 1 201939     1 2.77e-39   328.  1.45e-39\n 2 201939     2 6.41e- 4   299.  3.30e- 4\n 3 201939     3 7.23e- 4   273.  3.59e- 4\n 4 201939     4 7.91e- 4   248.  3.93e- 4\n 5 201939     5 8.69e- 4   226.  4.30e- 4\n 6 201939     6 9.54e- 4   206.  4.70e- 4\n 7 201939     7 1.05e- 3   188.  5.14e- 4\n 8 201939     8 1.15e- 3   171.  5.62e- 4\n 9 201939     9 1.27e- 3   156.  6.14e- 4\n10 201939    10 1.39e- 3   142.  6.70e- 4\n# ℹ 53,890 more rows\n\n\nIf you look closely, this returns 100 rows for each player in the data - because it is returning the coefficient for each player at each value of the lambda penalty. We can filter to the values for the optimal choice of lambda based on the cross-validation results, and then join our player names as before:\n\nrapm_ridge_coef &lt;- tidy_ridge_coef |&gt;\n  filter(lambda == fit_ridge_cv$lambda.min) |&gt;\n  # Convert term to numeric:\n  mutate(term = as.numeric(term)) |&gt;\n  # Now join the player names:\n  left_join(nba_player_table, by = c(\"term\" = \"player_id\"))\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION:\nNow, display the top 10 players based on coefficient estimates. What do you think of list in comparison to the APM results. Does this list pass the “eye test”? (Search who won the NBA MVP in 2023.)\nANSWER:\n\nrapm_ridge_coef |&gt;\n  slice_max(estimate, n = 10) |&gt;\n  dplyr::select(term, player_name, estimate)\n\n# A tibble: 10 × 3\n      term player_name     estimate\n     &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n 1  203954 Joel Embiid         5.37\n 2  203999 Nikola Jokic        4.59\n 3 1629027 Trae Young          4.28\n 4 1627783 Pascal Siakam       4.02\n 5 1628973 Jalen Brunson       3.64\n 6  201567 Kevin Love          3.59\n 7  203110 Draymond Green      3.56\n 8  201572 Brook Lopez         3.28\n 9  203076 Anthony Davis       3.24\n10 1629627 Zion Williamson     3.22\n\n\nConsidering Embiid won the MVP last season, this list definitely passes the eye test (it’s honestly amazing how well this works for basketball data). For context, let’s view the bottom 10:\n\nrapm_ridge_coef |&gt;\n  slice_min(estimate, n = 10) |&gt;\n  dplyr::select(term, player_name, estimate)\n\n# A tibble: 10 × 3\n      term player_name        estimate\n     &lt;dbl&gt; &lt;chr&gt;                 &lt;dbl&gt;\n 1 1630558 Davion Mitchell       -3.92\n 2 1630170 Devin Vassell         -3.86\n 3 1629670 Jordan Nwora          -3.11\n 4 1630598 Aaron Wiggins         -3.06\n 5  203210 JaMychal Green        -3.02\n 6 1630528 Josh Christopher      -2.95\n 7 1630586 Usman Garuba          -2.93\n 8 1631128 Christian Braun       -2.86\n 9  203115 Will Barton           -2.59\n10 1630197 Aleksej Pokusevski    -2.45\n\n\n\n\n\n\n\n\n\n\nActive Exercise\n\n\n\nQUESTION: Similar to before, create a visualization displaying the distribution of the player coefficients from this ridge regression RAPM. Describe what you observe about this distribution and how it compares to the APM coefficient distribution.\nANSWER:\n\nrapm_ridge_coef |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram() +\n  labs(x = \"RAPM estimate\", y = \"Count\") +\n  theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can see that the RAPM coefficients also appear to roughly follow a Normal-like distribution, but we no longer observe extreme tails. Additionally, we can see that the center for this distribution is approximately 0! The use of penalization has shrunk players towards 0, serving as the average baseline for players. This leads to a nice interpretation that coefficients above 0 are above average in performance, while below 0 are below average in performance.",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nba Rapm",
      "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#discussion",
    "href": "module_resources/nba-rapm/intro_nba_rapm_SOLUTIONS.html#discussion",
    "title": "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)",
    "section": "Discussion",
    "text": "Discussion\nYou have now learned the basics behind RAPM models in the context of studying NBA player effects. We demonstrated how RAPM improves upon the simpler APM model, but there are still further questions and extensions to explore:\n\nEvaluating and tuning RAPM models: We only considered tuning the \\(\\lambda\\) penalty via the default cross-validation in glmnet that relies on the observation-level response variable which in this case was the margin during an individual shift. However, the ultimate goal of the RAPM player coefficients could be for predicting game outcomes between two teams. One could tune the choice of \\(\\lambda\\) based on predicting the game outcomes as a difference between the sum of the home and away team ratings.\nAlternative choices for design matrix: There is flexibility in the design matrix for RAPM models. We only considered the home/away version of the matrix in this module, but we could specify an alternative set-up so that offense and defense effects are estimated separately. This type of approach would split the shifts into possessions where one team is on offense and the other is on defense. Each player has two columns - one indicator column if they were on offense during the possession and another indicator if there were on defense. This provides two measures of player performance but can be more difficult to fit appropriately since this is doubling the dimensionality of the problem.\nPrior information: This module only considered estimating player performance based on the observed appearances in games. But what if we have prior knowledge to tease apart players who often appear on the court together? We could account for priors via a Bayesian version of the RAPM model. Details of this type of approach will be left to be covered in a future module!",
    "crumbs": [
      "Home",
      "Module Resources",
      "Nba Rapm",
      "INSTRUCTOR SOLUTIONS: Introduction to regularized adjusted plus-minus (RAPM)"
    ]
  },
  {
    "objectID": "football/nfl-elo-ratings.html",
    "href": "football/nfl-elo-ratings.html",
    "title": "Introduction to Elo ratings",
    "section": "",
    "text": "Elo ratings are one of the most popular approaches for estimating player/team strength across a variety of sports. You can find a number of different sports examples maintained by sportswriter Neil Paine, as well as older versions that were featured in the popular website FiveThirtyEight. These dynamic ratings are adjusted for opponent strength and can be used for historical comparisons, such as who is the greatest tennis player of all time?, and for predicting outcomes. In this module you will learn the basics of Elo ratings in the context of measuring NFL team strength, walking through steps to implement and assess Elo ratings from scratch in R.",
    "crumbs": [
      "Home",
      "Football",
      "Introduction to Elo ratings"
    ]
  },
  {
    "objectID": "football/nfl-elo-ratings.html#motivation",
    "href": "football/nfl-elo-ratings.html#motivation",
    "title": "Introduction to Elo ratings",
    "section": "",
    "text": "Elo ratings are one of the most popular approaches for estimating player/team strength across a variety of sports. You can find a number of different sports examples maintained by sportswriter Neil Paine, as well as older versions that were featured in the popular website FiveThirtyEight. These dynamic ratings are adjusted for opponent strength and can be used for historical comparisons, such as who is the greatest tennis player of all time?, and for predicting outcomes. In this module you will learn the basics of Elo ratings in the context of measuring NFL team strength, walking through steps to implement and assess Elo ratings from scratch in R.",
    "crumbs": [
      "Home",
      "Football",
      "Introduction to Elo ratings"
    ]
  },
  {
    "objectID": "football/nfl-elo-ratings.html#learning-objectives",
    "href": "football/nfl-elo-ratings.html#learning-objectives",
    "title": "Introduction to Elo ratings",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this module, you will be able to:\n\nCompute the expected outcome or predicted probability based on player/team ratings.\nUpdate ratings following the observed outcome of a match/game.\nImplement the complete Elo ratings framework in R for a full NFL season.\nAssess Elo rating predictions using Brier score.\nTune the update factor and other settings to yield more optimal predictions.",
    "crumbs": [
      "Home",
      "Football",
      "Introduction to Elo ratings"
    ]
  },
  {
    "objectID": "football/nfl-elo-ratings.html#data",
    "href": "football/nfl-elo-ratings.html#data",
    "title": "Introduction to Elo ratings",
    "section": "Data",
    "text": "Data\nThe dataset and description are available at the SCORE Network Data Repository.",
    "crumbs": [
      "Home",
      "Football",
      "Introduction to Elo ratings"
    ]
  },
  {
    "objectID": "football/nfl-elo-ratings.html#module-materials",
    "href": "football/nfl-elo-ratings.html#module-materials",
    "title": "Introduction to Elo ratings",
    "section": "Module Materials",
    "text": "Module Materials\n\n\n\n\n\n\nPrerequisites\n\n\n\nPrior to working on through this module, students are expected to know the following:\n\nFamiliar with R with the ability to read and write functions.\nSome exposure to predicting outcomes with probabilities.\n\nThe module has sections indicating which portions are challenging exercises, and is designed to take an undergraduate student roughly 3-4 hours to complete.\n\n\nStudent assignment qmd file\nView instructor solutions",
    "crumbs": [
      "Home",
      "Football",
      "Introduction to Elo ratings"
    ]
  }
]